{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQzbmvQBQzIY"
   },
   "source": [
    "# Home Credit Default Risk (HCDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Functionized Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.externals import joblib\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import timeit\n",
    "import uuid\n",
    "\n",
    "config_file = os.path.join(os.getcwd(), \"workingdir.config\")\n",
    "with open(config_file, 'r') as f:\n",
    "    WORKING_DIR = f.readline()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, 'Data')\n",
    "LOG_DIR = os.path.join(WORKING_DIR, 'runs')\n",
    "\n",
    "def load_data(name):\n",
    "    in_path = os.path.join(DATA_DIR, f'{name}.csv')\n",
    "    df = pd.read_csv(in_path)\n",
    "    return df\n",
    "\n",
    "def get_datasets(phase):\n",
    "    datasets = {}\n",
    "    datasets[\"application\"] = load_data(f\"application_{phase}\")\n",
    "    print(f\"loaded {len(datasets['application'])} records\")\n",
    "    ds_names = (\"bureau\",\"bureau_balance\",\"credit_card_balance\",\"installments_payments\",\n",
    "            \"previous_application\",\"POS_CASH_balance\")\n",
    "    for ds_name in ds_names:\n",
    "        datasets[ds_name] = load_data(ds_name)\n",
    "    return datasets\n",
    "\n",
    "def features_from_previous_application(X, datasets):\n",
    "    '''\n",
    "    creates the no_prev_appl and no_approved_prev_appl columns\n",
    "    '''\n",
    "    prev_app = datasets['previous_application']\n",
    "    no_app_customer = prev_app.loc[(prev_app.DAYS_DECISION >= -365) & \n",
    "           (prev_app.NAME_CONTRACT_STATUS != 'Canceled'), ].groupby('SK_ID_CURR').SK_ID_PREV.count().sort_values(ascending=False) # only select the applications in the past 12 months\n",
    "    no_app_customer = no_app_customer.to_frame()\n",
    "    no_app_customer.reset_index(inplace=True)\n",
    "    no_app_customer.rename(columns={'SK_ID_PREV':'no_prev_appl'}, inplace=True)\n",
    "    \n",
    "    no_approved_app_customer = prev_app.loc[(prev_app.DAYS_DECISION >= -365) & \n",
    "           (prev_app.NAME_CONTRACT_STATUS == 'Approved'), ].groupby('SK_ID_CURR').SK_ID_PREV.count().sort_values(ascending=False) # only select the applications in the past 12 months\n",
    "    no_approved_app_customer = no_approved_app_customer.to_frame()\n",
    "    no_approved_app_customer.reset_index(inplace=True)\n",
    "    no_approved_app_customer.rename(columns={'SK_ID_PREV':'no_approved_prev_appl'}, inplace=True)\n",
    "    \n",
    "    X = pd.merge(X, no_app_customer, on='SK_ID_CURR', how='left')\n",
    "    X = pd.merge(X, no_approved_app_customer, on='SK_ID_CURR', how='left')\n",
    "    X[['no_prev_appl']] = X[['no_prev_appl']].fillna(value=0)\n",
    "    X[['no_approved_prev_appl']] = X[['no_approved_prev_appl']].fillna(0)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def features_from_bureau(X, datasets):\n",
    "    '''\n",
    "    Engineered features:\n",
    "    - total_creditLimit\n",
    "    - no_of_loans \n",
    "    - ave_creditLimit\n",
    "    '''\n",
    "    bureau = datasets['bureau']\n",
    "    credit_sum = bureau[(bureau.CREDIT_ACTIVE == 'Active') & (bureau.CREDIT_CURRENCY == 'currency 1')] \\\n",
    "        .groupby('SK_ID_CURR').AMT_CREDIT_SUM.sum()\n",
    "    credit_sum = credit_sum.to_frame()\n",
    "    credit_sum.reset_index(inplace=True)\n",
    "    \n",
    "    no_loans = bureau[(bureau.CREDIT_ACTIVE == 'Active') & (bureau.CREDIT_CURRENCY == 'currency 1')] \\\n",
    "        .groupby('SK_ID_CURR').SK_ID_BUREAU.count()\n",
    "    no_loans = no_loans.to_frame()\n",
    "    no_loans.reset_index(inplace=True)\n",
    "    \n",
    "    bureau_info = pd.merge(credit_sum, no_loans, how='outer', on='SK_ID_CURR')\n",
    "    bureau_info.rename(columns={'AMT_CREDIT_SUM':'total_creditLimit', 'SK_ID_BUREAU':'no_of_loans'}, inplace=True)\n",
    "    bureau_info['ave_creditLimit'] = bureau_info.eval('total_creditLimit/no_of_loans')\n",
    "\n",
    "    X = pd.merge(X, bureau_info, on='SK_ID_CURR', how='left')\n",
    "    X[['total_creditLimit', 'no_of_loans', 'ave_creditLimit']] = X[['total_creditLimit', 'no_of_loans', 'ave_creditLimit']].fillna(0)\n",
    "\n",
    "    return X\n",
    "\n",
    "def features_from_credit_card_balance(X, datasets):\n",
    "    '''\n",
    "    Engineered features:\n",
    "    - utilization_CC\n",
    "    - payment_ratio_CC\n",
    "    - total_credit_limit_CC\n",
    "    '''\n",
    "    ccb = datasets['credit_card_balance']\n",
    "    creditCard_info = ccb[(ccb.MONTHS_BALANCE >= -24) & \n",
    "                          (ccb.NAME_CONTRACT_STATUS =='Active') &\n",
    "                          (ccb.AMT_CREDIT_LIMIT_ACTUAL > 0)] \\\n",
    "                    .groupby('SK_ID_CURR')['AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL', 'AMT_PAYMENT_TOTAL_CURRENT'].sum()\n",
    "    creditCard_info.reset_index(inplace=True)\n",
    "    \n",
    "    creditCard_info['utilization_CC'] = creditCard_info.eval('AMT_BALANCE/AMT_CREDIT_LIMIT_ACTUAL')\n",
    "    creditCard_info['payment_ratio_CC'] = creditCard_info.eval('AMT_PAYMENT_TOTAL_CURRENT/AMT_BALANCE')\n",
    "    creditCard_info.loc[creditCard_info.payment_ratio_CC.isnull(), 'payment_ratio_CC'] = 1\n",
    "    creditCard_info.loc[creditCard_info.payment_ratio_CC > 1, 'payment_ratio_CC'] = 1\n",
    "    creditCard_info.drop(columns=['AMT_BALANCE', 'AMT_PAYMENT_TOTAL_CURRENT'], inplace=True)\n",
    "    creditCard_info.rename(columns={'AMT_CREDIT_LIMIT_ACTUAL':'total_creditLimit_CC'}, inplace=True)\n",
    "    \n",
    "    X = pd.merge(X, creditCard_info, on='SK_ID_CURR', how='left')\n",
    "    return X # best fillna strategy will be left to grid search\n",
    "\n",
    "def features_from_installments_payments(X, datasets):\n",
    "    '''\n",
    "    Engineered features:\n",
    "    - past_due_times\n",
    "    '''\n",
    "    ip = datasets['installments_payments']\n",
    "    ip['past_due_times'] = (ip.eval('DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT') > 0).astype(int)\n",
    "    past_due_info = ip[ip['DAYS_INSTALMENT'] >= -730].groupby('SK_ID_CURR')['past_due_times'].sum() \n",
    "    past_due_info = past_due_info.to_frame()\n",
    "    past_due_info.reset_index(inplace=True)\n",
    "\n",
    "    X = pd.merge(X, past_due_info, on='SK_ID_CURR', how='left')\n",
    "    return X\n",
    "\n",
    "def features_from_application(X):\n",
    "    '''\n",
    "    Engineered features:\n",
    "    - credit_income_ratio\n",
    "    - annuity_income_ratio\n",
    "    - REGION_POPULATION_RELATIVE_flag\n",
    "    '''\n",
    "    X['credit_income_ratio'] = X.eval('AMT_CREDIT/AMT_INCOME_TOTAL') #credit to income ratio\n",
    "    X['annuity_income_ratio'] = X.eval('AMT_ANNUITY/AMT_INCOME_TOTAL') #annuity to income ratio\n",
    "    return X\n",
    "\n",
    "def build_ratio_features(X):\n",
    "    '''\n",
    "    take ratios of all 2-way combo of numerical features\n",
    "    '''\n",
    "    \n",
    "    # the following features come from Naimesh and Nishad @thank you\n",
    "    X['income_credit_percen'] = (\n",
    "        X.AMT_INCOME_TOTAL / X.AMT_CREDIT).replace(np.inf, 0)\n",
    "    X['fam_member_income'] = (\n",
    "        X.AMT_INCOME_TOTAL / X.CNT_FAM_MEMBERS).replace(np.inf, 0)\n",
    "    X['ann_incom_percen'] = (\n",
    "        X.AMT_ANNUITY / X.AMT_INCOME_TOTAL).replace(np.inf, 0)\n",
    "    X['new_employ_to_birth_ratio'] = (\n",
    "        X.DAYS_EMPLOYED / X.DAYS_BIRTH).replace(np.inf, 0)\n",
    "    X['new_credit_to_annuity'] = (\n",
    "        X['AMT_CREDIT'] / X['AMT_ANNUITY']).replace(np.inf, 0)\n",
    "    X['new_credit_to_goods_ratio'] = (\n",
    "        X['AMT_CREDIT'] / X['AMT_GOODS_PRICE']).replace(np.inf, 0)\n",
    "    X['new_car_to_birth_ratio'] = (\n",
    "        X['OWN_CAR_AGE'] / X['DAYS_BIRTH']).replace(np.inf, 0)\n",
    "    X['new_car_to_emp_ratio'] = (\n",
    "        X['OWN_CAR_AGE'] / X['DAYS_EMPLOYED']).replace(np.inf, 0)\n",
    "    X['new_inc_per_child'] = (\n",
    "        X['AMT_INCOME_TOTAL'] / (1 + X['CNT_CHILDREN'])).replace(np.inf, 0)\n",
    "          \n",
    "    return X\n",
    "          \n",
    "def build_features(datasets):\n",
    "    print(\"features from previous application\")\n",
    "    X = features_from_previous_application(datasets['application'], datasets)\n",
    "    print(\"features from bureau\")\n",
    "    X = features_from_bureau(X, datasets)\n",
    "    print(\"features from credit card balance\")\n",
    "    X = features_from_credit_card_balance(X, datasets)\n",
    "    print(\"features from installments\")\n",
    "    X = features_from_installments_payments(X, datasets)\n",
    "    print(\"features from application\")\n",
    "    X = features_from_application(X)\n",
    "    \n",
    "    #create new features are the ratio of two numerical features\n",
    "    X = build_ratio_features(X)\n",
    "          \n",
    "    return X\n",
    "\n",
    "          \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "def print_msg(X, **kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        print(value)\n",
    "    return X\n",
    "\n",
    "def get_standard_pipeline(cat_attribs, num_attribs, poly_degree=1):  \n",
    "#     import pdb; pdb.set_trace()\n",
    "    num_pipeline = Pipeline([\n",
    "        ('num_selector', DataFrameSelector(num_attribs)),\n",
    "        ('print_num_1', FunctionTransformer(print_msg, kw_args=dict(msg=\"num_selector\"), validate=False)),\n",
    "        ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "        ('print_num_2', FunctionTransformer(print_msg, kw_args=dict(msg=\"num_imputer\"), validate=False)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('print_num_3', FunctionTransformer(print_msg, kw_args=dict(msg=\"num_scaler\"), validate=False)), \n",
    "        ('polynomial', PolynomialFeatures(degree=poly_degree)),\n",
    "        ('print_num_done', FunctionTransformer(print_msg, kw_args=dict(msg=\"num_done\"), validate=False)),       \n",
    "    ])\n",
    "#     import pdb; pdb.set_trace()\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('cat_selector', DataFrameSelector(cat_attribs)),\n",
    "        ('print_cat_1', FunctionTransformer(print_msg, kw_args=dict(msg=\"cat_selector\"), validate=False)),\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value = 'N/A')),\n",
    "        ('print_cat_2', FunctionTransformer(print_msg, kw_args=dict(msg=\"cat_imputer\"), validate=False)),\n",
    "        ('ohe', OneHotEncoder(sparse=False, dtype=np.uint8, handle_unknown=\"ignore\")),\n",
    "        ('print_cat_done', FunctionTransformer(print_msg, kw_args=dict(msg=\"cat_done\"), validate=False))\n",
    "    ])\n",
    "    num_cat_pipeline = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_pipeline, num_attribs),\n",
    "            ('cat', cat_pipeline, cat_attribs)],\n",
    "        n_jobs = -1\n",
    "    )\n",
    "#    num_cat_pipeline = FeatureUnion(transformer_list = [\n",
    "#        (\"num_pipe\", num_pipeline),\n",
    "#        (\"cat_pipe\", cat_pipeline)\n",
    "#    ],\n",
    "#    n_jobs = 2\n",
    "#    )\n",
    "    return num_cat_pipeline\n",
    "\n",
    "# default_pipeline = get_standard_pipeline(cat_attribs, num_attribs)\n",
    "\n",
    "def pre_process(preproc_pipeline, phase = \"train\"):\n",
    "    '''\n",
    "    Performs all feature engineering, data munging, etc. in a standardized way    \n",
    "    Returns: (transformed) X, Y, (fitted) pipeline. If phase == \"test\", Y and pipeline will = None\n",
    "    '''\n",
    "    datasets = get_datasets(phase)\n",
    "    \n",
    "    if phase == \"train\":\n",
    "        Y = datasets['application']['TARGET']\n",
    "    else:\n",
    "        Y = None\n",
    "    \n",
    "    X = build_features(datasets)  \n",
    "\n",
    "    print(\"start pipeline\")\n",
    "#     import pdb; pdb.set_trace()\n",
    "    if phase == \"train\":\n",
    "#         import pdb; pdb.set_trace()\n",
    "        X = preproc_pipeline.fit_transform(X)\n",
    "    else:\n",
    "        X = preproc_pipeline.transform(X)\n",
    "    \n",
    "    return X, Y, preproc_pipeline\n",
    "\n",
    "def get_search_class(search_repr):\n",
    "    return search_repr[:search_repr.find('(')]\n",
    "\n",
    "def get_clf(search_repr):\n",
    "    e_string = 'estimator='\n",
    "    start = search_repr.find(e_string) + len(e_string)\n",
    "    end = search_repr.find('),', start)\n",
    "    return search_repr[start:end+1]\n",
    "    \n",
    "def get_params(search_repr, is_grid = True):\n",
    "    if is_grid:\n",
    "        arg_string = 'param_grid='\n",
    "    else:\n",
    "        arg_string = 'param_distributions='\n",
    "    start = search_repr.find(arg_string) + len(arg_string)\n",
    "    end = search_repr.find('},', start)\n",
    "    return search_repr[start:end+1]\n",
    "\n",
    "def run_test(X, Y, \n",
    "             search, \n",
    "             test_description, \n",
    "             experiment_name, \n",
    "             pipeline_named_steps,\n",
    "             cat_attribs,\n",
    "             num_attribs,\n",
    "             testSize = 0.1, \n",
    "             **fit_params):\n",
    "    '''\n",
    "    Uses grid search to search for best model params\n",
    "    NOTE: set early stopping on the estimator you pass in!\n",
    "    Logs results, including best model (pickled), to mlflow\n",
    "    \n",
    "    Arguments:\n",
    "    `X` - training data - will be split into train and test sets\n",
    "    `Y` - targets\n",
    "    `search`- an instance of GridSearchCV or RandomizedSearchCV\n",
    "    `test_description` - description of test run to be logged\n",
    "    `experiment_name` - name of experiment that this test run is a part of\n",
    "    `pipeline_named_steps` - to be logged alongside metrics for future reference\n",
    "    `cat_attribs` - to be logged alongside metrics for future reference\n",
    "    `num_attribs` - to be logged alongside metrics for future reference\n",
    "    `testSize` - fraction of training set to hold out for sanity check/test \n",
    "    `fit_params` - additional parameters to be passed to the search .fit() function\n",
    "    '''\n",
    "    # train/test split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=testSize, random_state=42)\n",
    "    \n",
    "    # start log\n",
    "    search_repr = repr(search)\n",
    "    search_class = get_search_class(search_repr)\n",
    "    clf_repr = get_clf(search_repr)\n",
    "    params = get_params(search_repr)\n",
    "\n",
    "    run_attribs = []\n",
    "    run_attribs.append(wrap_in_quotes(experiment_name))   \n",
    "    run_attribs.append(wrap_in_quotes(test_description))\n",
    "    run_attribs.append(wrap_in_quotes(str(cat_attribs)))\n",
    "    run_attribs.append(wrap_in_quotes(str(num_attribs)))\n",
    "    run_attribs.append(wrap_in_quotes(pipeline_named_steps))\n",
    "    run_attribs.append(wrap_in_quotes(search_class))\n",
    "    run_attribs.append(wrap_in_quotes(params))\n",
    "    \n",
    "#     import pdb; pdb.set_trace()\n",
    "    search.fit(X_train, y_train, **fit_params)\n",
    "    cv_results = search.cv_results_\n",
    "\n",
    "    # TODO in phase 3: calculate p-value w.r.t. baseline \n",
    "\n",
    "    # sanity check with test set\n",
    "    verification = VerificationTest(search.best_estimator_)\n",
    "    verification.run(X_test, y_test)\n",
    "\n",
    "    # log: best params, auc, p-value, array of train loss, array of val loss\n",
    "    run_attribs.append(wrap_in_quotes(str(search.best_params_)))\n",
    "    run_attribs.append(format_num(mean(cv_results['mean_fit_time'])))\n",
    "    run_attribs.append(format_num(search.best_score_))\n",
    "    run_attribs.append(format_num(verification.test_auc))\n",
    "    run_attribs.append(format_num(verification.test_accuracy))\n",
    "    run_attribs.append(format_num(verification.prediction_ms_per_row))\n",
    "    run_id = str(uuid.uuid4())\n",
    "    run_attribs.append(wrap_in_quotes(run_id))\n",
    "    line = ','.join(run_attribs) + '\\n'\n",
    "    \n",
    "    with open(os.path.join(LOG_DIR, \"runs.csv\"), 'a') as run_file:\n",
    "        run_file.write(line)    \n",
    "        \n",
    "    # store best model\n",
    "    model_file = run_id + '.joblib'\n",
    "    joblib.dump(search.best_estimator_, os.path.join(LOG_DIR, model_file))\n",
    "\n",
    "class VerificationTest:\n",
    "    '''\n",
    "    Runs a verification test against held out test set. Calculates the following metrics,\n",
    "    which are available as properties:\n",
    "    * test_auc\n",
    "    * test_accuracy\n",
    "    * prediction_ms_per_row\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        '''\n",
    "        `model` = best_estimator_ from search\n",
    "        `significance_score` = Which metric used for p_value? Choose from ('auc', 'accuracy')\n",
    "        '''\n",
    "        self._model = model\n",
    "        \n",
    "    def run(self, X_test, y_test):\n",
    "        '''\n",
    "        `X_test`\n",
    "        `y_test`\n",
    "        '''\n",
    "        y_hat = self._model.predict(X_test)\n",
    "        self.test_accuracy = accuracy_score(y_test, y_hat)\n",
    "        \n",
    "        y_proba = self._model.predict_proba(X_test)\n",
    "        self.test_auc = roc_auc_score(y_test, y_proba[:,1])\n",
    "        \n",
    "        timing_test = wrapper(self._model.predict, X_test)\n",
    "        test_execution_time = timeit.timeit(timing_test, setup = gc.enable, number = 1)\n",
    "        self.prediction_ms_per_row = test_execution_time * 1000000 / len(y_test)\n",
    "                \n",
    "def wrapper(func, *args, **kwargs):\n",
    "    def wrapped():\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapped\n",
    "        \n",
    "def wrap_in_quotes(s):\n",
    "    s = s.replace('\"', '').replace('\\n', '').replace('\\r', '')\n",
    "    return '\"' + s + '\"'\n",
    "\n",
    "def format_num(n):\n",
    "    return str(round(n, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical and categorical features\n",
    "\n",
    "NUMERIC_COLS_logit = ['CNT_CHILDREN',\n",
    " 'AMT_INCOME_TOTAL',\n",
    " 'AMT_CREDIT',\n",
    " 'AMT_ANNUITY',\n",
    " 'AMT_GOODS_PRICE',\n",
    " 'REGION_POPULATION_RELATIVE',\n",
    " 'DAYS_BIRTH',\n",
    " 'DAYS_EMPLOYED',\n",
    " 'DAYS_REGISTRATION',\n",
    " 'DAYS_ID_PUBLISH',\n",
    " 'OWN_CAR_AGE',\n",
    " 'CNT_FAM_MEMBERS',\n",
    " 'HOUR_APPR_PROCESS_START',\n",
    " 'EXT_SOURCE_1',\n",
    " 'EXT_SOURCE_2',\n",
    " 'EXT_SOURCE_3',\n",
    " 'APARTMENTS_AVG',\n",
    " 'BASEMENTAREA_AVG',\n",
    " 'YEARS_BEGINEXPLUATATION_AVG',\n",
    " 'YEARS_BUILD_AVG',\n",
    " 'COMMONAREA_AVG',\n",
    " 'ELEVATORS_AVG',\n",
    " 'ENTRANCES_AVG',\n",
    " 'FLOORSMAX_AVG',\n",
    " 'FLOORSMIN_AVG',\n",
    " 'LANDAREA_AVG',\n",
    " 'LIVINGAPARTMENTS_AVG',\n",
    " 'LIVINGAREA_AVG',\n",
    " 'NONLIVINGAPARTMENTS_AVG',\n",
    " 'NONLIVINGAREA_AVG',\n",
    " 'APARTMENTS_MODE',\n",
    " 'BASEMENTAREA_MODE',\n",
    " 'YEARS_BEGINEXPLUATATION_MODE',\n",
    " 'YEARS_BUILD_MODE',\n",
    " 'COMMONAREA_MODE',\n",
    " 'ELEVATORS_MODE',\n",
    " 'ENTRANCES_MODE',\n",
    " 'FLOORSMAX_MODE',\n",
    " 'FLOORSMIN_MODE',\n",
    " 'LANDAREA_MODE',\n",
    " 'LIVINGAPARTMENTS_MODE',\n",
    " 'LIVINGAREA_MODE',\n",
    " 'NONLIVINGAPARTMENTS_MODE',\n",
    " 'NONLIVINGAREA_MODE',\n",
    " 'APARTMENTS_MEDI',\n",
    " 'BASEMENTAREA_MEDI',\n",
    " 'YEARS_BEGINEXPLUATATION_MEDI',\n",
    " 'YEARS_BUILD_MEDI',\n",
    " 'COMMONAREA_MEDI',\n",
    " 'ELEVATORS_MEDI',\n",
    " 'ENTRANCES_MEDI',\n",
    " 'FLOORSMAX_MEDI',\n",
    " 'FLOORSMIN_MEDI',\n",
    " 'LANDAREA_MEDI',\n",
    " 'LIVINGAPARTMENTS_MEDI',\n",
    " 'LIVINGAREA_MEDI',\n",
    " 'NONLIVINGAPARTMENTS_MEDI',\n",
    " 'NONLIVINGAREA_MEDI',\n",
    " 'TOTALAREA_MODE',\n",
    " 'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    " 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    " 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    " 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    " 'DAYS_LAST_PHONE_CHANGE',\n",
    " 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    " 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    " 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    " 'AMT_REQ_CREDIT_BUREAU_MON',\n",
    " 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    " 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    " 'no_prev_appl',\n",
    " 'no_approved_prev_appl',\n",
    " 'total_creditLimit',\n",
    " 'no_of_loans',\n",
    " 'ave_creditLimit',\n",
    " 'total_creditLimit_CC',\n",
    " 'utilization_CC',\n",
    " 'payment_ratio_CC',\n",
    " 'past_due_times',\n",
    " 'credit_income_ratio',\n",
    " 'annuity_income_ratio']\n",
    "\n",
    "CATEGORY_COLS_logit = ['NAME_CONTRACT_TYPE',\n",
    " 'CODE_GENDER',\n",
    " 'FLAG_OWN_CAR',\n",
    " 'FLAG_OWN_REALTY',\n",
    " 'NAME_TYPE_SUITE',\n",
    " 'NAME_INCOME_TYPE',\n",
    " 'NAME_EDUCATION_TYPE',\n",
    " 'NAME_FAMILY_STATUS',\n",
    " 'NAME_HOUSING_TYPE',\n",
    " 'FLAG_MOBIL',\n",
    " 'FLAG_EMP_PHONE',\n",
    " 'FLAG_WORK_PHONE',\n",
    " 'FLAG_CONT_MOBILE',\n",
    " 'FLAG_PHONE',\n",
    " 'FLAG_EMAIL',\n",
    " 'OCCUPATION_TYPE',\n",
    " 'REGION_RATING_CLIENT',\n",
    " 'REGION_RATING_CLIENT_W_CITY',\n",
    " 'WEEKDAY_APPR_PROCESS_START',\n",
    " 'REG_REGION_NOT_LIVE_REGION',\n",
    " 'REG_REGION_NOT_WORK_REGION',\n",
    " 'LIVE_REGION_NOT_WORK_REGION',\n",
    " 'REG_CITY_NOT_LIVE_CITY',\n",
    " 'REG_CITY_NOT_WORK_CITY',\n",
    " 'LIVE_CITY_NOT_WORK_CITY',\n",
    " 'ORGANIZATION_TYPE',\n",
    " 'FONDKAPREMONT_MODE',\n",
    " 'HOUSETYPE_MODE',\n",
    " 'WALLSMATERIAL_MODE',\n",
    " 'EMERGENCYSTATE_MODE',\n",
    " 'FLAG_DOCUMENT_2',\n",
    " 'FLAG_DOCUMENT_3',\n",
    " 'FLAG_DOCUMENT_4',\n",
    " 'FLAG_DOCUMENT_5',\n",
    " 'FLAG_DOCUMENT_6',\n",
    " 'FLAG_DOCUMENT_7',\n",
    " 'FLAG_DOCUMENT_8',\n",
    " 'FLAG_DOCUMENT_9',\n",
    " 'FLAG_DOCUMENT_10',\n",
    " 'FLAG_DOCUMENT_11',\n",
    " 'FLAG_DOCUMENT_12',\n",
    " 'FLAG_DOCUMENT_13',\n",
    " 'FLAG_DOCUMENT_14',\n",
    " 'FLAG_DOCUMENT_15',\n",
    " 'FLAG_DOCUMENT_16',\n",
    " 'FLAG_DOCUMENT_17',\n",
    " 'FLAG_DOCUMENT_18',\n",
    " 'FLAG_DOCUMENT_19',\n",
    " 'FLAG_DOCUMENT_20',\n",
    " 'FLAG_DOCUMENT_21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import losses, metrics, optimizers\n",
    "from keras.callbacks import EarlyStopping, ProgbarLogger\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, AlphaDropout, Dense, Dropout, Input \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def get_keras_model(architecture = [298, 128, 128], \n",
    "                    activation_fn = 'relu', \n",
    "                    drop_fraction = None):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LAYERS\n",
    "    # input\n",
    "    model.add(Dense(architecture[1], input_shape = (architecture[0],), activation = activation_fn)) \n",
    "    if drop_fraction:\n",
    "        model.add(Dropout(drop_fraction))\n",
    "    \n",
    "    # features/weights\n",
    "    for i in range(2, len(architecture)):\n",
    "        model.add(Dense(architecture[i], activation = activation_fn))\n",
    "        if drop_fraction:\n",
    "            model.add(Dropout(drop_fraction))\n",
    "            \n",
    "    # output\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # other hyper-parameters\n",
    "    opt = optimizers.Adadelta()\n",
    "    loss_fn = losses.binary_crossentropy\n",
    "    mets = [metrics.binary_accuracy]\n",
    "    \n",
    "    # compile and return\n",
    "    model.compile(optimizer = opt, loss = loss_fn, metrics = mets)\n",
    "    return model\n",
    "\n",
    "def get_selu_activation_model(architecture = [298, 256, 256], \n",
    "                    drop_fraction = None):\n",
    "    '''\n",
    "    Cannot use get_keras_model because we need different algorithms for weight initialization and dropout\n",
    "    '''\n",
    "    activation_fn = 'selu'\n",
    "    wt_init = 'lecun_normal'\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LAYERS\n",
    "    # input\n",
    "    model.add(Dense(architecture[1], \n",
    "                    input_shape = (architecture[0],), \n",
    "                    activation = activation_fn, \n",
    "                    kernel_initializer = wt_init))\n",
    "    if drop_fraction:\n",
    "        model.add(AlphaDropout(drop_fraction))\n",
    "    \n",
    "    # features/weights\n",
    "    for i in range(2, len(architecture)):\n",
    "        model.add(Dense(architecture[i], activation = activation_fn, kernel_initializer = wt_init))\n",
    "        if drop_fraction:\n",
    "            model.add(AlphaDropout(drop_fraction))\n",
    "            \n",
    "    # output\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # other hyper-parameters\n",
    "    opt = optimizers.Adadelta()\n",
    "    loss_fn = losses.binary_crossentropy\n",
    "    mets = [metrics.binary_accuracy]\n",
    "    \n",
    "    # compile and return\n",
    "    model.compile(optimizer = opt, loss = loss_fn, metrics = mets)\n",
    "    return model\n",
    "    \n",
    "def get_pipe_named_steps(pipeline):\n",
    "    named_steps = ''\n",
    "    for pipe in pipeline.transformers_[:-1]:\n",
    "        named_steps += str(pipe[1].named_steps)\n",
    "    named_steps += str(pipeline.transformers_[-1])\n",
    "    return named_steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:643: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] drop_fraction=None ..............................................\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.3585 - binary_accuracy: 0.8560 - val_loss: 0.2606 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.2640 - binary_accuracy: 0.9187 - val_loss: 0.2506 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2574 - binary_accuracy: 0.9187 - val_loss: 0.2466 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2544 - binary_accuracy: 0.9187 - val_loss: 0.2463 - val_binary_accuracy: 0.9216\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2529 - binary_accuracy: 0.9187 - val_loss: 0.2436 - val_binary_accuracy: 0.9216\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2520 - binary_accuracy: 0.9187 - val_loss: 0.2429 - val_binary_accuracy: 0.9215\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2513 - binary_accuracy: 0.9188 - val_loss: 0.2430 - val_binary_accuracy: 0.9216\n",
      "[CV] ..... drop_fraction=None, score=0.7448473144609622, total=   6.9s\n",
      "[CV] drop_fraction=None ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.3211 - binary_accuracy: 0.8931 - val_loss: 0.2581 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.2594 - binary_accuracy: 0.9196 - val_loss: 0.2481 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2531 - binary_accuracy: 0.9196 - val_loss: 0.2444 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2507 - binary_accuracy: 0.9196 - val_loss: 0.2431 - val_binary_accuracy: 0.9218\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2496 - binary_accuracy: 0.9197 - val_loss: 0.2419 - val_binary_accuracy: 0.9218\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2490 - binary_accuracy: 0.9197 - val_loss: 0.2415 - val_binary_accuracy: 0.9218\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2487 - binary_accuracy: 0.9197 - val_loss: 0.2413 - val_binary_accuracy: 0.9217\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2479 - binary_accuracy: 0.9197 - val_loss: 0.2430 - val_binary_accuracy: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   16.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... drop_fraction=None, score=0.745481301743778, total=   7.9s\n",
      "[CV] drop_fraction=None ..............................................\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.3727 - binary_accuracy: 0.8523 - val_loss: 0.2661 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.2617 - binary_accuracy: 0.9193 - val_loss: 0.2561 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2550 - binary_accuracy: 0.9193 - val_loss: 0.2528 - val_binary_accuracy: 0.9196\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2525 - binary_accuracy: 0.9193 - val_loss: 0.2514 - val_binary_accuracy: 0.9196\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2511 - binary_accuracy: 0.9194 - val_loss: 0.2511 - val_binary_accuracy: 0.9198\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2504 - binary_accuracy: 0.9194 - val_loss: 0.2504 - val_binary_accuracy: 0.9196\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2496 - binary_accuracy: 0.9194 - val_loss: 0.2497 - val_binary_accuracy: 0.9197\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2488 - binary_accuracy: 0.9194 - val_loss: 0.2497 - val_binary_accuracy: 0.9197\n",
      "[CV] ..... drop_fraction=None, score=0.7470472474258668, total=   8.0s\n",
      "[CV] drop_fraction=0.25 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   24.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.3339 - binary_accuracy: 0.8896 - val_loss: 0.2593 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.2729 - binary_accuracy: 0.9186 - val_loss: 0.2508 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2670 - binary_accuracy: 0.9185 - val_loss: 0.2476 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2642 - binary_accuracy: 0.9185 - val_loss: 0.2457 - val_binary_accuracy: 0.9218\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2619 - binary_accuracy: 0.9186 - val_loss: 0.2446 - val_binary_accuracy: 0.9218\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2607 - binary_accuracy: 0.9186 - val_loss: 0.2437 - val_binary_accuracy: 0.9218\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2594 - binary_accuracy: 0.9187 - val_loss: 0.2429 - val_binary_accuracy: 0.9218\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2576 - binary_accuracy: 0.9187 - val_loss: 0.2426 - val_binary_accuracy: 0.9218\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.2567 - binary_accuracy: 0.9187 - val_loss: 0.2420 - val_binary_accuracy: 0.9219\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.2563 - binary_accuracy: 0.9187 - val_loss: 0.2420 - val_binary_accuracy: 0.9217\n",
      "[CV] ..... drop_fraction=0.25, score=0.7483977688825729, total=  12.8s\n",
      "[CV] drop_fraction=0.25 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   38.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.3221 - binary_accuracy: 0.9056 - val_loss: 0.2606 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.2727 - binary_accuracy: 0.9196 - val_loss: 0.2496 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2651 - binary_accuracy: 0.9194 - val_loss: 0.2455 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2616 - binary_accuracy: 0.9195 - val_loss: 0.2441 - val_binary_accuracy: 0.9219\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2595 - binary_accuracy: 0.9195 - val_loss: 0.2452 - val_binary_accuracy: 0.9219\n",
      "[CV] ..... drop_fraction=0.25, score=0.7356270097035199, total=   7.2s\n",
      "[CV] drop_fraction=0.25 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   46.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.3583 - binary_accuracy: 0.8693 - val_loss: 0.2649 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.2741 - binary_accuracy: 0.9191 - val_loss: 0.2566 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2667 - binary_accuracy: 0.9191 - val_loss: 0.2533 - val_binary_accuracy: 0.9196\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2633 - binary_accuracy: 0.9190 - val_loss: 0.2525 - val_binary_accuracy: 0.9196\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2608 - binary_accuracy: 0.9190 - val_loss: 0.2510 - val_binary_accuracy: 0.9197\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2591 - binary_accuracy: 0.9191 - val_loss: 0.2502 - val_binary_accuracy: 0.9196\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.2580 - binary_accuracy: 0.9193 - val_loss: 0.2501 - val_binary_accuracy: 0.9196\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.2579 - binary_accuracy: 0.9191 - val_loss: 0.2503 - val_binary_accuracy: 0.9196\n",
      "[CV] ..... drop_fraction=0.25, score=0.7440576105714417, total=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   58.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   58.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 249083 samples, validate on 27676 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.3317 - binary_accuracy: 0.8747 - val_loss: 0.2520 - val_binary_accuracy: 0.9224\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.2571 - binary_accuracy: 0.9191 - val_loss: 0.2459 - val_binary_accuracy: 0.9224\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2530 - binary_accuracy: 0.9191 - val_loss: 0.2443 - val_binary_accuracy: 0.9222\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.2513 - binary_accuracy: 0.9191 - val_loss: 0.2433 - val_binary_accuracy: 0.9222\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.2505 - binary_accuracy: 0.9190 - val_loss: 0.2423 - val_binary_accuracy: 0.9220\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.2498 - binary_accuracy: 0.9191 - val_loss: 0.2466 - val_binary_accuracy: 0.9214\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience = 1, restore_best_weights = True)\n",
    "clf = KerasClassifier(build_fn = get_keras_model, \n",
    "                      batch_size = 10240, \n",
    "                      validation_split = 0.1, \n",
    "                      epochs = 20, \n",
    "                      verbose = 2)\n",
    "search_grid = {'drop_fraction':[None, 0.25]}\n",
    "gs = GridSearchCV(\n",
    "    estimator = clf,\n",
    "    param_grid = search_grid,\n",
    "    scoring = 'roc_auc',  \n",
    "    cv = 3,\n",
    "    verbose=10,\n",
    "    fit_params = {'callbacks': [early_stopping]}\n",
    ")\n",
    "\n",
    "# run test\n",
    "run_test(X, Y, \n",
    "         search = gs, \n",
    "         experiment_name = \"NN\", \n",
    "         test_description = 'initial NN with 128-128 and dropout of None or 0.25',\n",
    "         pipeline_named_steps = get_pipe_named_steps(lgbm_pipeline), \n",
    "         num_attribs = NUMERIC_COLS_lgbm, \n",
    "         cat_attribs = CATEGORY_COLS_lgbm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 307511 records\n",
      "features from previous application\n",
      "features from bureau\n",
      "features from credit card balance\n",
      "features from installments\n",
      "features from application\n",
      "start pipeline\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f19ca51965e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc_pipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m clf = KerasClassifier(build_fn = get_keras_model, \n\u001b[0;32m      6\u001b[0m                       \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit)\n",
    "X, Y, pipe = pre_process(phase = \"train\", preproc_pipeline = pipeline)\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 1, restore_best_weights = True)\n",
    "clf = KerasClassifier(build_fn = get_keras_model, \n",
    "                      validation_split = 0.1, \n",
    "                      epochs = 25, \n",
    "                      verbose = 2)\n",
    "search_grid = {'drop_fraction':[None, 0.25], \n",
    "               'architecture':[[298,1024,1024],[298,512,512],[298,256,256]],\n",
    "               'batch_size':[8,32]}\n",
    "gs = GridSearchCV(\n",
    "    estimator = clf,\n",
    "    param_grid = search_grid,\n",
    "    scoring = 'roc_auc',  \n",
    "    cv = 3,\n",
    "    verbose=10,\n",
    "    fit_params = {'callbacks': [early_stopping]}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:643: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=8, drop_fraction=None \n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 84s - loss: 0.2660 - binary_accuracy: 0.9186 - val_loss: 0.2472 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 81s - loss: 0.2657 - binary_accuracy: 0.9187 - val_loss: 0.2534 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=8, drop_fraction=None, score=0.7242726725904918, total= 2.9min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=8, drop_fraction=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 82s - loss: 0.2639 - binary_accuracy: 0.9196 - val_loss: 0.2544 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 81s - loss: 0.2632 - binary_accuracy: 0.9196 - val_loss: 0.2507 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 81s - loss: 0.2632 - binary_accuracy: 0.9196 - val_loss: 0.2496 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/25\n",
      " - 82s - loss: 0.2629 - binary_accuracy: 0.9196 - val_loss: 0.2562 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=8, drop_fraction=None, score=0.7333799771880454, total= 5.5min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=8, drop_fraction=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 83s - loss: 0.2652 - binary_accuracy: 0.9192 - val_loss: 0.2561 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 82s - loss: 0.2637 - binary_accuracy: 0.9193 - val_loss: 0.2591 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=8, drop_fraction=None, score=0.7274613902873297, total= 2.9min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=8, drop_fraction=0.25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 11.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 88s - loss: 0.2777 - binary_accuracy: 0.9185 - val_loss: 0.2645 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 87s - loss: 0.2814 - binary_accuracy: 0.9187 - val_loss: 0.2883 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=8, drop_fraction=0.25, score=0.7124201199125946, total= 3.1min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=8, drop_fraction=0.25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 15.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 90s - loss: 0.2749 - binary_accuracy: 0.9196 - val_loss: 0.2598 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 89s - loss: 0.2787 - binary_accuracy: 0.9196 - val_loss: 0.2663 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=8, drop_fraction=0.25, score=0.7155013280631977, total= 3.1min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=8, drop_fraction=0.25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 18.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 90s - loss: 0.2769 - binary_accuracy: 0.9192 - val_loss: 0.2696 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 89s - loss: 0.2834 - binary_accuracy: 0.9192 - val_loss: 0.2757 - val_binary_accuracy: 0.9197\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=8, drop_fraction=0.25, score=0.719243629367416, total= 3.1min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=32, drop_fraction=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 21.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 22s - loss: 0.2585 - binary_accuracy: 0.9187 - val_loss: 0.2480 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.2547 - binary_accuracy: 0.9187 - val_loss: 0.2479 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 21s - loss: 0.2535 - binary_accuracy: 0.9188 - val_loss: 0.2417 - val_binary_accuracy: 0.9218\n",
      "Epoch 4/25\n",
      " - 22s - loss: 0.2531 - binary_accuracy: 0.9188 - val_loss: 0.2419 - val_binary_accuracy: 0.9205\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=32, drop_fraction=None, score=0.7446104770460023, total= 1.5min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=32, drop_fraction=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 23.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 22s - loss: 0.2563 - binary_accuracy: 0.9196 - val_loss: 0.2475 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2529 - binary_accuracy: 0.9197 - val_loss: 0.2543 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=32, drop_fraction=None, score=0.740074883906393, total=  46.0s\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=32, drop_fraction=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 24.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 22s - loss: 0.2568 - binary_accuracy: 0.9192 - val_loss: 0.2525 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.2533 - binary_accuracy: 0.9193 - val_loss: 0.2522 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 22s - loss: 0.2526 - binary_accuracy: 0.9193 - val_loss: 0.2541 - val_binary_accuracy: 0.9198\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=32, drop_fraction=None, score=0.7419713648699664, total= 1.1min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=32, drop_fraction=0.25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 25.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 24s - loss: 0.2625 - binary_accuracy: 0.9185 - val_loss: 0.2423 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2590 - binary_accuracy: 0.9187 - val_loss: 0.2466 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=32, drop_fraction=0.25, score=0.7392518829164154, total=  49.9s\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 24s - loss: 0.2596 - binary_accuracy: 0.9195 - val_loss: 0.2449 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2570 - binary_accuracy: 0.9196 - val_loss: 0.2432 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 23s - loss: 0.2563 - binary_accuracy: 0.9196 - val_loss: 0.2504 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=32, drop_fraction=0.25, score=0.7406565029458219, total= 1.2min\n",
      "[CV] architecture=[298, 1024, 1024], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 24s - loss: 0.2604 - binary_accuracy: 0.9191 - val_loss: 0.2535 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2577 - binary_accuracy: 0.9193 - val_loss: 0.2551 - val_binary_accuracy: 0.9197\n",
      "[CV]  architecture=[298, 1024, 1024], batch_size=32, drop_fraction=0.25, score=0.7314137296602735, total=  50.2s\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 66s - loss: 0.2660 - binary_accuracy: 0.9187 - val_loss: 0.2487 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 65s - loss: 0.2657 - binary_accuracy: 0.9187 - val_loss: 0.2567 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=None, score=0.727128589689326, total= 2.3min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 65s - loss: 0.2633 - binary_accuracy: 0.9196 - val_loss: 0.2490 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 65s - loss: 0.2638 - binary_accuracy: 0.9196 - val_loss: 0.2591 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=None, score=0.7258531365602802, total= 2.3min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 66s - loss: 0.2635 - binary_accuracy: 0.9192 - val_loss: 0.2601 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 65s - loss: 0.2639 - binary_accuracy: 0.9193 - val_loss: 0.2589 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 65s - loss: 0.2635 - binary_accuracy: 0.9192 - val_loss: 0.2615 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=None, score=0.7244624630404384, total= 3.4min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 69s - loss: 0.2755 - binary_accuracy: 0.9187 - val_loss: 0.2529 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 68s - loss: 0.2793 - binary_accuracy: 0.9187 - val_loss: 0.2563 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25, score=0.7229938800761031, total= 2.4min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 70s - loss: 0.2743 - binary_accuracy: 0.9196 - val_loss: 0.2717 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 69s - loss: 0.2764 - binary_accuracy: 0.9196 - val_loss: 0.2597 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 69s - loss: 0.2777 - binary_accuracy: 0.9196 - val_loss: 0.2708 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25, score=0.7125043787605723, total= 3.6min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 70s - loss: 0.2732 - binary_accuracy: 0.9192 - val_loss: 0.2654 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 69s - loss: 0.2775 - binary_accuracy: 0.9193 - val_loss: 0.2753 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25, score=0.7137328455282718, total= 2.5min\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2575 - binary_accuracy: 0.9187 - val_loss: 0.2491 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2538 - binary_accuracy: 0.9187 - val_loss: 0.2479 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2532 - binary_accuracy: 0.9187 - val_loss: 0.2444 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2528 - binary_accuracy: 0.9188 - val_loss: 0.2456 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=None, score=0.7468204963821823, total= 1.2min\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2555 - binary_accuracy: 0.9196 - val_loss: 0.2464 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2521 - binary_accuracy: 0.9197 - val_loss: 0.2412 - val_binary_accuracy: 0.9220\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2515 - binary_accuracy: 0.9197 - val_loss: 0.2400 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2506 - binary_accuracy: 0.9197 - val_loss: 0.2435 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=None, score=0.7468202653555426, total= 1.2min\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2561 - binary_accuracy: 0.9190 - val_loss: 0.2504 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2529 - binary_accuracy: 0.9193 - val_loss: 0.2559 - val_binary_accuracy: 0.9197\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=None, score=0.7450059448818567, total=  39.3s\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2615 - binary_accuracy: 0.9185 - val_loss: 0.2422 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2578 - binary_accuracy: 0.9187 - val_loss: 0.2511 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25, score=0.7439065338681893, total=  41.3s\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2597 - binary_accuracy: 0.9196 - val_loss: 0.2436 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2558 - binary_accuracy: 0.9196 - val_loss: 0.2540 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25, score=0.741830022391222, total=  41.9s\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2599 - binary_accuracy: 0.9192 - val_loss: 0.2520 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2570 - binary_accuracy: 0.9193 - val_loss: 0.2636 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25, score=0.7418071442919432, total=  41.6s\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 63s - loss: 0.2654 - binary_accuracy: 0.9187 - val_loss: 0.2489 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 62s - loss: 0.2636 - binary_accuracy: 0.9187 - val_loss: 0.2453 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 62s - loss: 0.2638 - binary_accuracy: 0.9187 - val_loss: 0.2492 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=None, score=0.731770614216182, total= 3.3min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 65s - loss: 0.2642 - binary_accuracy: 0.9196 - val_loss: 0.2519 - val_binary_accuracy: 0.9219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      " - 62s - loss: 0.2631 - binary_accuracy: 0.9196 - val_loss: 0.2588 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=None, score=0.7222821011394849, total= 2.3min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 64s - loss: 0.2645 - binary_accuracy: 0.9193 - val_loss: 0.2622 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 62s - loss: 0.2637 - binary_accuracy: 0.9192 - val_loss: 0.2623 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=None, score=0.7255510891894679, total= 2.3min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 68s - loss: 0.2733 - binary_accuracy: 0.9187 - val_loss: 0.2502 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 66s - loss: 0.2744 - binary_accuracy: 0.9187 - val_loss: 0.2599 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25, score=0.7208961265438469, total= 2.4min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 68s - loss: 0.2701 - binary_accuracy: 0.9196 - val_loss: 0.2545 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 67s - loss: 0.2726 - binary_accuracy: 0.9196 - val_loss: 0.2562 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25, score=0.7126706851996646, total= 2.4min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 68s - loss: 0.2725 - binary_accuracy: 0.9193 - val_loss: 0.2713 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 67s - loss: 0.2744 - binary_accuracy: 0.9193 - val_loss: 0.2663 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 67s - loss: 0.2771 - binary_accuracy: 0.9192 - val_loss: 0.2762 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25, score=0.7181097231818993, total= 3.6min\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2567 - binary_accuracy: 0.9185 - val_loss: 0.2410 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2533 - binary_accuracy: 0.9187 - val_loss: 0.2427 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=None, score=0.7459188095740066, total=  38.7s\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2549 - binary_accuracy: 0.9196 - val_loss: 0.2396 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2515 - binary_accuracy: 0.9197 - val_loss: 0.2404 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=None, score=0.7459849474768105, total=  38.9s\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2551 - binary_accuracy: 0.9193 - val_loss: 0.2500 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2517 - binary_accuracy: 0.9193 - val_loss: 0.2526 - val_binary_accuracy: 0.9204\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=None, score=0.7500711418576429, total=  39.3s\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2615 - binary_accuracy: 0.9186 - val_loss: 0.2411 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2574 - binary_accuracy: 0.9187 - val_loss: 0.2421 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25, score=0.7442815167806994, total=  41.8s\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2599 - binary_accuracy: 0.9195 - val_loss: 0.2446 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2558 - binary_accuracy: 0.9196 - val_loss: 0.2412 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2553 - binary_accuracy: 0.9196 - val_loss: 0.2538 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25, score=0.7435035289911909, total= 1.0min\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2601 - binary_accuracy: 0.9191 - val_loss: 0.2530 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2563 - binary_accuracy: 0.9193 - val_loss: 0.2506 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2555 - binary_accuracy: 0.9193 - val_loss: 0.2520 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25, score=0.7467900077169132, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 75.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 249083 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 27s - loss: 0.2548 - binary_accuracy: 0.9191 - val_loss: 0.2406 - val_binary_accuracy: 0.9225\n",
      "Epoch 2/25\n",
      " - 26s - loss: 0.2522 - binary_accuracy: 0.9191 - val_loss: 0.2430 - val_binary_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "# run test\n",
    "run_test(X, Y, \n",
    "         search = gs, \n",
    "         experiment_name = \"NN\", \n",
    "         test_description = 'larger architectures, relu activation, smaller mini-batches',\n",
    "         pipeline_named_steps = get_pipe_named_steps(pipeline), \n",
    "         num_attribs = NUMERIC_COLS_logit, \n",
    "         cat_attribs = CATEGORY_COLS_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELU activation \n",
    "\n",
    "Klambauer, et al. proposed [\"self-normalizing neural networks\"](https://arxiv.org/abs/1706.02515) that use scaled exponential linear unit (SELU) activation. This activation makes the weight vectors converge toward zero mean and unit variance, which allows training to explore the parameter space without encountering exploding or disappearing gradients. Consequently, feed-forward networks can explore a larger parameter space for more epochs--or so the hypothesis goes. Let us see for ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:643: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=None ..\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 67s - loss: 0.2694 - binary_accuracy: 0.9175 - val_loss: 0.2508 - val_binary_accuracy: 0.9217\n",
      "Epoch 2/25\n",
      " - 64s - loss: 0.2651 - binary_accuracy: 0.9176 - val_loss: 0.2508 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 64s - loss: 0.2657 - binary_accuracy: 0.9176 - val_loss: 0.2451 - val_binary_accuracy: 0.9218\n",
      "Epoch 4/25\n",
      " - 64s - loss: 0.2655 - binary_accuracy: 0.9176 - val_loss: 0.2553 - val_binary_accuracy: 0.9196\n",
      "Epoch 5/25\n",
      " - 64s - loss: 0.2664 - binary_accuracy: 0.9172 - val_loss: 0.2485 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=None, score=0.7289892235670072, total= 5.5min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=None ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 64s - loss: 0.2675 - binary_accuracy: 0.9181 - val_loss: 0.2468 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 64s - loss: 0.2635 - binary_accuracy: 0.9188 - val_loss: 0.2452 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 64s - loss: 0.2637 - binary_accuracy: 0.9186 - val_loss: 0.2554 - val_binary_accuracy: 0.9218\n",
      "Epoch 4/25\n",
      " - 64s - loss: 0.2639 - binary_accuracy: 0.9186 - val_loss: 0.2541 - val_binary_accuracy: 0.9215\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=None, score=0.727110365504903, total= 4.4min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=None ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 10.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 65s - loss: 0.2689 - binary_accuracy: 0.9179 - val_loss: 0.2555 - val_binary_accuracy: 0.9197\n",
      "Epoch 2/25\n",
      " - 64s - loss: 0.2639 - binary_accuracy: 0.9186 - val_loss: 0.2873 - val_binary_accuracy: 0.9195\n",
      "Epoch 3/25\n",
      " - 64s - loss: 0.2638 - binary_accuracy: 0.9183 - val_loss: 0.3141 - val_binary_accuracy: 0.9089\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=None, score=0.7317616970871867, total= 3.4min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 14.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 70s - loss: 0.2759 - binary_accuracy: 0.9170 - val_loss: 0.4012 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 69s - loss: 0.2733 - binary_accuracy: 0.9170 - val_loss: 0.3559 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 69s - loss: 0.2748 - binary_accuracy: 0.9170 - val_loss: 0.4833 - val_binary_accuracy: 0.9218\n",
      "Epoch 4/25\n",
      " - 69s - loss: 0.2747 - binary_accuracy: 0.9168 - val_loss: 0.3055 - val_binary_accuracy: 0.9220\n",
      "Epoch 5/25\n",
      " - 69s - loss: 0.2757 - binary_accuracy: 0.9167 - val_loss: 0.3979 - val_binary_accuracy: 0.9219\n",
      "Epoch 6/25\n",
      " - 69s - loss: 0.2761 - binary_accuracy: 0.9169 - val_loss: 0.3939 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25, score=0.7182504395798047, total= 7.1min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 21.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 70s - loss: 0.2736 - binary_accuracy: 0.9175 - val_loss: 0.3113 - val_binary_accuracy: 0.9200\n",
      "Epoch 2/25\n",
      " - 69s - loss: 0.2716 - binary_accuracy: 0.9179 - val_loss: 0.4005 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 69s - loss: 0.2719 - binary_accuracy: 0.9179 - val_loss: 0.5130 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25, score=0.7165752765849227, total= 3.6min\n",
      "[CV] architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 25.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 70s - loss: 0.2749 - binary_accuracy: 0.9169 - val_loss: 0.4062 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 70s - loss: 0.2721 - binary_accuracy: 0.9179 - val_loss: 0.3833 - val_binary_accuracy: 0.9195\n",
      "Epoch 3/25\n",
      " - 70s - loss: 0.2728 - binary_accuracy: 0.9174 - val_loss: 0.4369 - val_binary_accuracy: 0.9196\n",
      "Epoch 4/25\n",
      " - 70s - loss: 0.2730 - binary_accuracy: 0.9177 - val_loss: 0.3916 - val_binary_accuracy: 0.9194\n",
      "[CV]  architecture=[298, 512, 512], batch_size=8, drop_fraction=0.25, score=0.7301354533342069, total= 4.8min\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=None .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 30.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2645 - binary_accuracy: 0.9167 - val_loss: 0.2554 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2553 - binary_accuracy: 0.9182 - val_loss: 0.2454 - val_binary_accuracy: 0.9217\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2545 - binary_accuracy: 0.9185 - val_loss: 0.2425 - val_binary_accuracy: 0.9220\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2536 - binary_accuracy: 0.9185 - val_loss: 0.2432 - val_binary_accuracy: 0.9219\n",
      "Epoch 5/25\n",
      " - 17s - loss: 0.2527 - binary_accuracy: 0.9185 - val_loss: 0.2533 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=None, score=0.7507895689201971, total= 1.4min\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=None .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 31.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2627 - binary_accuracy: 0.9175 - val_loss: 0.2428 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2532 - binary_accuracy: 0.9194 - val_loss: 0.2437 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2519 - binary_accuracy: 0.9193 - val_loss: 0.2490 - val_binary_accuracy: 0.9216\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=None, score=0.7393693745570437, total=  53.5s\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=None .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 32.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2613 - binary_accuracy: 0.9178 - val_loss: 0.2526 - val_binary_accuracy: 0.9199\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2535 - binary_accuracy: 0.9190 - val_loss: 0.2595 - val_binary_accuracy: 0.9171\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2525 - binary_accuracy: 0.9191 - val_loss: 0.2554 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=None, score=0.7489278427858065, total=  54.0s\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 33.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2661 - binary_accuracy: 0.9169 - val_loss: 0.3455 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2590 - binary_accuracy: 0.9180 - val_loss: 0.3503 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2587 - binary_accuracy: 0.9182 - val_loss: 0.2988 - val_binary_accuracy: 0.8895\n",
      "Epoch 4/25\n",
      " - 18s - loss: 0.2582 - binary_accuracy: 0.9182 - val_loss: 0.3278 - val_binary_accuracy: 0.9217\n",
      "Epoch 5/25\n",
      " - 18s - loss: 0.2580 - binary_accuracy: 0.9181 - val_loss: 0.3210 - val_binary_accuracy: 0.9213\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25, score=0.7429062374958055, total= 1.6min\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2641 - binary_accuracy: 0.9179 - val_loss: 0.3179 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2569 - binary_accuracy: 0.9190 - val_loss: 0.3190 - val_binary_accuracy: 0.9217\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2566 - binary_accuracy: 0.9192 - val_loss: 0.3280 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25, score=0.7395467775595529, total=  58.2s\n",
      "[CV] architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2649 - binary_accuracy: 0.9176 - val_loss: 0.2709 - val_binary_accuracy: 0.9200\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2577 - binary_accuracy: 0.9187 - val_loss: 0.2973 - val_binary_accuracy: 0.9197\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2571 - binary_accuracy: 0.9187 - val_loss: 0.2986 - val_binary_accuracy: 0.9157\n",
      "[CV]  architecture=[298, 512, 512], batch_size=32, drop_fraction=0.25, score=0.7456920856137355, total=  58.8s\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 63s - loss: 0.2646 - binary_accuracy: 0.9180 - val_loss: 0.2428 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 62s - loss: 0.2611 - binary_accuracy: 0.9185 - val_loss: 0.2652 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 62s - loss: 0.2616 - binary_accuracy: 0.9183 - val_loss: 0.2452 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=None, score=0.7366496152789412, total= 3.3min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 63s - loss: 0.2632 - binary_accuracy: 0.9188 - val_loss: 0.2577 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 62s - loss: 0.2589 - binary_accuracy: 0.9193 - val_loss: 0.2561 - val_binary_accuracy: 0.9220\n",
      "Epoch 3/25\n",
      " - 62s - loss: 0.2595 - binary_accuracy: 0.9195 - val_loss: 0.2451 - val_binary_accuracy: 0.9215\n",
      "Epoch 4/25\n",
      " - 62s - loss: 0.2596 - binary_accuracy: 0.9192 - val_loss: 0.2633 - val_binary_accuracy: 0.9219\n",
      "Epoch 5/25\n",
      " - 62s - loss: 0.2593 - binary_accuracy: 0.9192 - val_loss: 0.2517 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=None, score=0.7263106471716642, total= 5.4min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=None ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 63s - loss: 0.2632 - binary_accuracy: 0.9184 - val_loss: 0.2641 - val_binary_accuracy: 0.9177\n",
      "Epoch 2/25\n",
      " - 63s - loss: 0.2600 - binary_accuracy: 0.9190 - val_loss: 0.2639 - val_binary_accuracy: 0.9204\n",
      "Epoch 3/25\n",
      " - 63s - loss: 0.2601 - binary_accuracy: 0.9189 - val_loss: 0.2592 - val_binary_accuracy: 0.9196\n",
      "Epoch 4/25\n",
      " - 63s - loss: 0.2603 - binary_accuracy: 0.9189 - val_loss: 0.2533 - val_binary_accuracy: 0.9196\n",
      "Epoch 5/25\n",
      " - 63s - loss: 0.2606 - binary_accuracy: 0.9187 - val_loss: 0.2534 - val_binary_accuracy: 0.9196\n",
      "Epoch 6/25\n",
      " - 63s - loss: 0.2615 - binary_accuracy: 0.9189 - val_loss: 0.2555 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=None, score=0.7371908529145987, total= 6.5min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 68s - loss: 0.2688 - binary_accuracy: 0.9178 - val_loss: 0.3902 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 69s - loss: 0.2663 - binary_accuracy: 0.9182 - val_loss: 0.3412 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 70s - loss: 0.2668 - binary_accuracy: 0.9181 - val_loss: 0.3316 - val_binary_accuracy: 0.9217\n",
      "Epoch 4/25\n",
      " - 69s - loss: 0.2674 - binary_accuracy: 0.9181 - val_loss: 0.4781 - val_binary_accuracy: 0.9221\n",
      "Epoch 5/25\n",
      " - 68s - loss: 0.2677 - binary_accuracy: 0.9180 - val_loss: 0.4088 - val_binary_accuracy: 0.9218\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25, score=0.7288448935838479, total= 5.9min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 69s - loss: 0.2675 - binary_accuracy: 0.9188 - val_loss: 0.3043 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 68s - loss: 0.2644 - binary_accuracy: 0.9193 - val_loss: 0.3983 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 68s - loss: 0.2648 - binary_accuracy: 0.9192 - val_loss: 0.3823 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25, score=0.7279361677843196, total= 3.6min\n",
      "[CV] architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25 ..\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 69s - loss: 0.2678 - binary_accuracy: 0.9185 - val_loss: 0.3316 - val_binary_accuracy: 0.9197\n",
      "Epoch 2/25\n",
      " - 68s - loss: 0.2646 - binary_accuracy: 0.9189 - val_loss: 0.4215 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 68s - loss: 0.2653 - binary_accuracy: 0.9188 - val_loss: 0.4125 - val_binary_accuracy: 0.9197\n",
      "[CV]  architecture=[298, 256, 256], batch_size=8, drop_fraction=0.25, score=0.7222265723403286, total= 3.6min\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2615 - binary_accuracy: 0.9172 - val_loss: 0.2448 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 16s - loss: 0.2536 - binary_accuracy: 0.9187 - val_loss: 0.2508 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 16s - loss: 0.2526 - binary_accuracy: 0.9184 - val_loss: 0.2413 - val_binary_accuracy: 0.9220\n",
      "Epoch 4/25\n",
      " - 16s - loss: 0.2520 - binary_accuracy: 0.9186 - val_loss: 0.2457 - val_binary_accuracy: 0.9218\n",
      "Epoch 5/25\n",
      " - 16s - loss: 0.2515 - binary_accuracy: 0.9186 - val_loss: 0.2464 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=None, score=0.7469120067805565, total= 1.4min\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2592 - binary_accuracy: 0.9183 - val_loss: 0.2405 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2516 - binary_accuracy: 0.9195 - val_loss: 0.2445 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2506 - binary_accuracy: 0.9194 - val_loss: 0.2399 - val_binary_accuracy: 0.9220\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2500 - binary_accuracy: 0.9195 - val_loss: 0.2476 - val_binary_accuracy: 0.9189\n",
      "Epoch 5/25\n",
      " - 17s - loss: 0.2495 - binary_accuracy: 0.9195 - val_loss: 0.2399 - val_binary_accuracy: 0.9220\n",
      "Epoch 6/25\n",
      " - 17s - loss: 0.2493 - binary_accuracy: 0.9195 - val_loss: 0.2422 - val_binary_accuracy: 0.9220\n",
      "Epoch 7/25\n",
      " - 17s - loss: 0.2488 - binary_accuracy: 0.9198 - val_loss: 0.2440 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=None, score=0.7467585253728467, total= 2.0min\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=None .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2590 - binary_accuracy: 0.9181 - val_loss: 0.2530 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2523 - binary_accuracy: 0.9192 - val_loss: 0.2599 - val_binary_accuracy: 0.9197\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2511 - binary_accuracy: 0.9192 - val_loss: 0.2525 - val_binary_accuracy: 0.9195\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2506 - binary_accuracy: 0.9191 - val_loss: 0.2509 - val_binary_accuracy: 0.9196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n",
      " - 17s - loss: 0.2500 - binary_accuracy: 0.9192 - val_loss: 0.2509 - val_binary_accuracy: 0.9203\n",
      "Epoch 6/25\n",
      " - 17s - loss: 0.2496 - binary_accuracy: 0.9192 - val_loss: 0.2612 - val_binary_accuracy: 0.9199\n",
      "Epoch 7/25\n",
      " - 17s - loss: 0.2491 - binary_accuracy: 0.9193 - val_loss: 0.2499 - val_binary_accuracy: 0.9202\n",
      "Epoch 8/25\n",
      " - 17s - loss: 0.2488 - binary_accuracy: 0.9192 - val_loss: 0.2485 - val_binary_accuracy: 0.9200\n",
      "Epoch 9/25\n",
      " - 17s - loss: 0.2486 - binary_accuracy: 0.9191 - val_loss: 0.2574 - val_binary_accuracy: 0.9197\n",
      "Epoch 10/25\n",
      " - 17s - loss: 0.2482 - binary_accuracy: 0.9194 - val_loss: 0.2544 - val_binary_accuracy: 0.9201\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=None, score=0.7482451574474822, total= 2.9min\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2627 - binary_accuracy: 0.9177 - val_loss: 0.3534 - val_binary_accuracy: 0.9202\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2561 - binary_accuracy: 0.9184 - val_loss: 0.2659 - val_binary_accuracy: 0.9216\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2553 - binary_accuracy: 0.9184 - val_loss: 0.3113 - val_binary_accuracy: 0.9214\n",
      "Epoch 4/25\n",
      " - 18s - loss: 0.2551 - binary_accuracy: 0.9184 - val_loss: 0.2589 - val_binary_accuracy: 0.9214\n",
      "Epoch 5/25\n",
      " - 18s - loss: 0.2546 - binary_accuracy: 0.9184 - val_loss: 0.3300 - val_binary_accuracy: 0.9219\n",
      "Epoch 6/25\n",
      " - 18s - loss: 0.2545 - binary_accuracy: 0.9185 - val_loss: 0.3242 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25, score=0.7465765454095667, total= 1.9min\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2616 - binary_accuracy: 0.9184 - val_loss: 0.2519 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2542 - binary_accuracy: 0.9193 - val_loss: 0.2947 - val_binary_accuracy: 0.9221\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2535 - binary_accuracy: 0.9192 - val_loss: 0.2824 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25, score=0.7436220628535086, total=  59.2s\n",
      "[CV] architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25 .\n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2613 - binary_accuracy: 0.9181 - val_loss: 0.3058 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2548 - binary_accuracy: 0.9193 - val_loss: 0.3851 - val_binary_accuracy: 0.9195\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2542 - binary_accuracy: 0.9190 - val_loss: 0.3467 - val_binary_accuracy: 0.9195\n",
      "[CV]  architecture=[298, 256, 256], batch_size=32, drop_fraction=0.25, score=0.7445603897995383, total=  59.3s\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 79s - loss: 0.2747 - binary_accuracy: 0.9169 - val_loss: 0.2577 - val_binary_accuracy: 0.9218\n",
      "Epoch 2/25\n",
      " - 78s - loss: 0.2667 - binary_accuracy: 0.9176 - val_loss: 0.2536 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 79s - loss: 0.2686 - binary_accuracy: 0.9179 - val_loss: 0.2533 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/25\n",
      " - 78s - loss: 0.2704 - binary_accuracy: 0.9178 - val_loss: 0.2514 - val_binary_accuracy: 0.9215\n",
      "Epoch 5/25\n",
      " - 78s - loss: 0.2711 - binary_accuracy: 0.9175 - val_loss: 0.2489 - val_binary_accuracy: 0.9218\n",
      "Epoch 6/25\n",
      " - 78s - loss: 0.2718 - binary_accuracy: 0.9173 - val_loss: 0.2446 - val_binary_accuracy: 0.9220\n",
      "Epoch 7/25\n",
      " - 78s - loss: 0.2713 - binary_accuracy: 0.9175 - val_loss: 0.2503 - val_binary_accuracy: 0.9209\n",
      "Epoch 8/25\n",
      " - 78s - loss: 0.2704 - binary_accuracy: 0.9171 - val_loss: 0.2910 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=None, score=0.7405911994374805, total=10.6min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 79s - loss: 0.2716 - binary_accuracy: 0.9180 - val_loss: 0.2511 - val_binary_accuracy: 0.9218\n",
      "Epoch 2/25\n",
      " - 78s - loss: 0.2648 - binary_accuracy: 0.9188 - val_loss: 0.2480 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 81s - loss: 0.2663 - binary_accuracy: 0.9186 - val_loss: 0.2522 - val_binary_accuracy: 0.9136\n",
      "Epoch 4/25\n",
      " - 83s - loss: 0.2676 - binary_accuracy: 0.9186 - val_loss: 0.2637 - val_binary_accuracy: 0.9213\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=None, score=0.728886482559529, total= 5.6min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 80s - loss: 0.2711 - binary_accuracy: 0.9177 - val_loss: 0.2588 - val_binary_accuracy: 0.9198\n",
      "Epoch 2/25\n",
      " - 79s - loss: 0.2647 - binary_accuracy: 0.9185 - val_loss: 0.2610 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 79s - loss: 0.2663 - binary_accuracy: 0.9184 - val_loss: 0.2806 - val_binary_accuracy: 0.9192\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=None, score=0.7366634966138811, total= 4.2min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 86s - loss: 0.2726 - binary_accuracy: 0.9179 - val_loss: 0.3461 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 85s - loss: 0.2694 - binary_accuracy: 0.9181 - val_loss: 0.3640 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 85s - loss: 0.2709 - binary_accuracy: 0.9183 - val_loss: 0.3625 - val_binary_accuracy: 0.9203\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=0.25, score=0.7313382766959554, total= 4.5min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 86s - loss: 0.2709 - binary_accuracy: 0.9184 - val_loss: 0.3419 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 85s - loss: 0.2677 - binary_accuracy: 0.9191 - val_loss: 0.3033 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 85s - loss: 0.2683 - binary_accuracy: 0.9192 - val_loss: 0.4098 - val_binary_accuracy: 0.9206\n",
      "Epoch 4/25\n",
      " - 85s - loss: 0.2694 - binary_accuracy: 0.9192 - val_loss: 0.4321 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=0.25, score=0.7260789170642898, total= 5.9min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 87s - loss: 0.2710 - binary_accuracy: 0.9182 - val_loss: 0.4046 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 86s - loss: 0.2685 - binary_accuracy: 0.9187 - val_loss: 0.3919 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 86s - loss: 0.2694 - binary_accuracy: 0.9186 - val_loss: 0.4206 - val_binary_accuracy: 0.9196\n",
      "Epoch 4/25\n",
      " - 86s - loss: 0.2707 - binary_accuracy: 0.9186 - val_loss: 0.5379 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=8, drop_fraction=0.25, score=0.7294364325414138, total= 6.0min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 22s - loss: 0.2643 - binary_accuracy: 0.9169 - val_loss: 0.2523 - val_binary_accuracy: 0.9208\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2557 - binary_accuracy: 0.9184 - val_loss: 0.2498 - val_binary_accuracy: 0.9156\n",
      "Epoch 3/25\n",
      " - 21s - loss: 0.2546 - binary_accuracy: 0.9184 - val_loss: 0.2583 - val_binary_accuracy: 0.9217\n",
      "Epoch 4/25\n",
      " - 21s - loss: 0.2539 - binary_accuracy: 0.9184 - val_loss: 0.2492 - val_binary_accuracy: 0.9220\n",
      "Epoch 5/25\n",
      " - 21s - loss: 0.2534 - binary_accuracy: 0.9183 - val_loss: 0.2559 - val_binary_accuracy: 0.9216\n",
      "Epoch 6/25\n",
      " - 21s - loss: 0.2530 - binary_accuracy: 0.9185 - val_loss: 0.2437 - val_binary_accuracy: 0.9218\n",
      "Epoch 7/25\n",
      " - 21s - loss: 0.2527 - binary_accuracy: 0.9183 - val_loss: 0.2428 - val_binary_accuracy: 0.9219\n",
      "Epoch 8/25\n",
      " - 21s - loss: 0.2524 - binary_accuracy: 0.9184 - val_loss: 0.2426 - val_binary_accuracy: 0.9217\n",
      "Epoch 9/25\n",
      " - 21s - loss: 0.2520 - binary_accuracy: 0.9184 - val_loss: 0.2460 - val_binary_accuracy: 0.9215\n",
      "Epoch 10/25\n",
      " - 21s - loss: 0.2515 - binary_accuracy: 0.9183 - val_loss: 0.2490 - val_binary_accuracy: 0.9210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=None, score=0.7450741783434739, total= 3.6min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 22s - loss: 0.2653 - binary_accuracy: 0.9172 - val_loss: 0.2755 - val_binary_accuracy: 0.9221\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2540 - binary_accuracy: 0.9192 - val_loss: 0.2486 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 21s - loss: 0.2530 - binary_accuracy: 0.9194 - val_loss: 0.2580 - val_binary_accuracy: 0.9220\n",
      "Epoch 4/25\n",
      " - 21s - loss: 0.2524 - binary_accuracy: 0.9193 - val_loss: 0.2407 - val_binary_accuracy: 0.9221\n",
      "Epoch 5/25\n",
      " - 21s - loss: 0.2516 - binary_accuracy: 0.9194 - val_loss: 0.2722 - val_binary_accuracy: 0.9220\n",
      "Epoch 6/25\n",
      " - 21s - loss: 0.2510 - binary_accuracy: 0.9194 - val_loss: 0.2439 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=None, score=0.7491279370633239, total= 2.2min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 23s - loss: 0.2635 - binary_accuracy: 0.9176 - val_loss: 0.2683 - val_binary_accuracy: 0.9189\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2541 - binary_accuracy: 0.9190 - val_loss: 0.2602 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 21s - loss: 0.2529 - binary_accuracy: 0.9191 - val_loss: 0.2667 - val_binary_accuracy: 0.9152\n",
      "Epoch 4/25\n",
      " - 21s - loss: 0.2518 - binary_accuracy: 0.9190 - val_loss: 0.2786 - val_binary_accuracy: 0.8983\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=None, score=0.7321886729736246, total= 1.5min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 24s - loss: 0.2645 - binary_accuracy: 0.9173 - val_loss: 0.3237 - val_binary_accuracy: 0.9212\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.2578 - binary_accuracy: 0.9184 - val_loss: 0.3864 - val_binary_accuracy: 0.9155\n",
      "Epoch 3/25\n",
      " - 22s - loss: 0.2569 - binary_accuracy: 0.9184 - val_loss: 0.3298 - val_binary_accuracy: 0.9202\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=0.25, score=0.7481187602318056, total= 1.2min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 24s - loss: 0.2628 - binary_accuracy: 0.9186 - val_loss: 0.3325 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2556 - binary_accuracy: 0.9192 - val_loss: 0.2579 - val_binary_accuracy: 0.9152\n",
      "Epoch 3/25\n",
      " - 23s - loss: 0.2550 - binary_accuracy: 0.9194 - val_loss: 0.2837 - val_binary_accuracy: 0.9168\n",
      "Epoch 4/25\n",
      " - 23s - loss: 0.2547 - binary_accuracy: 0.9192 - val_loss: 0.3679 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=0.25, score=0.7453459217870587, total= 1.6min\n",
      "[CV] architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 25s - loss: 0.2630 - binary_accuracy: 0.9181 - val_loss: 0.2756 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2564 - binary_accuracy: 0.9188 - val_loss: 0.3302 - val_binary_accuracy: 0.9181\n",
      "Epoch 3/25\n",
      " - 23s - loss: 0.2554 - binary_accuracy: 0.9188 - val_loss: 0.3326 - val_binary_accuracy: 0.9207\n",
      "[CV]  architecture=[298, 512, 512, 256], batch_size=32, drop_fraction=0.25, score=0.7437948894276446, total= 1.3min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 79s - loss: 0.2663 - binary_accuracy: 0.9178 - val_loss: 0.2461 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 78s - loss: 0.2615 - binary_accuracy: 0.9186 - val_loss: 0.2629 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 77s - loss: 0.2615 - binary_accuracy: 0.9184 - val_loss: 0.2637 - val_binary_accuracy: 0.9220\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=None, score=0.7284778197769158, total= 4.1min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 79s - loss: 0.2640 - binary_accuracy: 0.9188 - val_loss: 0.2526 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 78s - loss: 0.2588 - binary_accuracy: 0.9194 - val_loss: 0.2477 - val_binary_accuracy: 0.9218\n",
      "Epoch 3/25\n",
      " - 78s - loss: 0.2592 - binary_accuracy: 0.9194 - val_loss: 0.2537 - val_binary_accuracy: 0.9220\n",
      "Epoch 4/25\n",
      " - 78s - loss: 0.2603 - binary_accuracy: 0.9194 - val_loss: 0.2462 - val_binary_accuracy: 0.9214\n",
      "Epoch 5/25\n",
      " - 77s - loss: 0.2607 - binary_accuracy: 0.9193 - val_loss: 0.2481 - val_binary_accuracy: 0.9220\n",
      "Epoch 6/25\n",
      " - 78s - loss: 0.2613 - binary_accuracy: 0.9193 - val_loss: 0.2733 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=None, score=0.7330538639161213, total= 8.0min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 80s - loss: 0.2642 - binary_accuracy: 0.9184 - val_loss: 0.2564 - val_binary_accuracy: 0.9197\n",
      "Epoch 2/25\n",
      " - 78s - loss: 0.2586 - binary_accuracy: 0.9191 - val_loss: 0.2526 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 78s - loss: 0.2588 - binary_accuracy: 0.9190 - val_loss: 0.2607 - val_binary_accuracy: 0.9198\n",
      "Epoch 4/25\n",
      " - 78s - loss: 0.2606 - binary_accuracy: 0.9191 - val_loss: 0.2535 - val_binary_accuracy: 0.9202\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=None, score=0.7391939983476721, total= 5.5min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 89s - loss: 0.2686 - binary_accuracy: 0.9182 - val_loss: 0.3391 - val_binary_accuracy: 0.9213\n",
      "Epoch 2/25\n",
      " - 87s - loss: 0.2658 - binary_accuracy: 0.9186 - val_loss: 0.3742 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 86s - loss: 0.2667 - binary_accuracy: 0.9186 - val_loss: 0.4173 - val_binary_accuracy: 0.9217\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=0.25, score=0.7270584847271158, total= 4.6min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 90s - loss: 0.2661 - binary_accuracy: 0.9193 - val_loss: 0.4020 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 87s - loss: 0.2639 - binary_accuracy: 0.9195 - val_loss: 0.3762 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 87s - loss: 0.2650 - binary_accuracy: 0.9194 - val_loss: 0.3963 - val_binary_accuracy: 0.9219\n",
      "Epoch 4/25\n",
      " - 87s - loss: 0.2659 - binary_accuracy: 0.9195 - val_loss: 0.3664 - val_binary_accuracy: 0.9219\n",
      "Epoch 5/25\n",
      " - 87s - loss: 0.2672 - binary_accuracy: 0.9195 - val_loss: 0.4082 - val_binary_accuracy: 0.9219\n",
      "Epoch 6/25\n",
      " - 87s - loss: 0.2663 - binary_accuracy: 0.9196 - val_loss: 0.3437 - val_binary_accuracy: 0.9219\n",
      "Epoch 7/25\n",
      " - 87s - loss: 0.2678 - binary_accuracy: 0.9195 - val_loss: 0.4124 - val_binary_accuracy: 0.9219\n",
      "Epoch 8/25\n",
      " - 87s - loss: 0.2680 - binary_accuracy: 0.9193 - val_loss: 0.4261 - val_binary_accuracy: 0.9219\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=0.25, score=0.7306810996402319, total=11.9min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 89s - loss: 0.2670 - binary_accuracy: 0.9188 - val_loss: 0.3892 - val_binary_accuracy: 0.9196\n",
      "Epoch 2/25\n",
      " - 87s - loss: 0.2643 - binary_accuracy: 0.9191 - val_loss: 0.4262 - val_binary_accuracy: 0.9196\n",
      "Epoch 3/25\n",
      " - 87s - loss: 0.2656 - binary_accuracy: 0.9192 - val_loss: 0.4186 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=8, drop_fraction=0.25, score=0.7280355989914795, total= 4.6min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 23s - loss: 0.2623 - binary_accuracy: 0.9174 - val_loss: 0.2416 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2538 - binary_accuracy: 0.9185 - val_loss: 0.2435 - val_binary_accuracy: 0.9203\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 21s - loss: 0.2527 - binary_accuracy: 0.9186 - val_loss: 0.2444 - val_binary_accuracy: 0.9216\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=None, score=0.745016733387099, total= 1.2min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 23s - loss: 0.2596 - binary_accuracy: 0.9186 - val_loss: 0.2436 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2521 - binary_accuracy: 0.9197 - val_loss: 0.2450 - val_binary_accuracy: 0.9220\n",
      "Epoch 3/25\n",
      " - 21s - loss: 0.2508 - binary_accuracy: 0.9193 - val_loss: 0.2411 - val_binary_accuracy: 0.9220\n",
      "Epoch 4/25\n",
      " - 21s - loss: 0.2503 - binary_accuracy: 0.9196 - val_loss: 0.2404 - val_binary_accuracy: 0.9218\n",
      "Epoch 5/25\n",
      " - 21s - loss: 0.2498 - binary_accuracy: 0.9196 - val_loss: 0.2437 - val_binary_accuracy: 0.9203\n",
      "Epoch 6/25\n",
      " - 21s - loss: 0.2495 - binary_accuracy: 0.9196 - val_loss: 0.2469 - val_binary_accuracy: 0.9207\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=None, score=0.7493074545562814, total= 2.2min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=None \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 23s - loss: 0.2601 - binary_accuracy: 0.9180 - val_loss: 0.2523 - val_binary_accuracy: 0.9199\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2518 - binary_accuracy: 0.9192 - val_loss: 0.2512 - val_binary_accuracy: 0.9198\n",
      "Epoch 3/25\n",
      " - 21s - loss: 0.2512 - binary_accuracy: 0.9192 - val_loss: 0.2513 - val_binary_accuracy: 0.9196\n",
      "Epoch 4/25\n",
      " - 21s - loss: 0.2507 - binary_accuracy: 0.9191 - val_loss: 0.2519 - val_binary_accuracy: 0.9196\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=None, score=0.7416926435616706, total= 1.5min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 26s - loss: 0.2628 - binary_accuracy: 0.9178 - val_loss: 0.3330 - val_binary_accuracy: 0.9219\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2561 - binary_accuracy: 0.9185 - val_loss: 0.3405 - val_binary_accuracy: 0.9206\n",
      "Epoch 3/25\n",
      " - 23s - loss: 0.2551 - binary_accuracy: 0.9185 - val_loss: 0.3563 - val_binary_accuracy: 0.9172\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=0.25, score=0.7450420318110367, total= 1.3min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 26s - loss: 0.2596 - binary_accuracy: 0.9188 - val_loss: 0.2925 - val_binary_accuracy: 0.9091\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2543 - binary_accuracy: 0.9193 - val_loss: 0.3646 - val_binary_accuracy: 0.9219\n",
      "Epoch 3/25\n",
      " - 23s - loss: 0.2535 - binary_accuracy: 0.9194 - val_loss: 0.3243 - val_binary_accuracy: 0.9204\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=0.25, score=0.7411701138525766, total= 1.3min\n",
      "[CV] architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=0.25 \n",
      "Train on 166055 samples, validate on 18451 samples\n",
      "Epoch 1/25\n",
      " - 26s - loss: 0.2616 - binary_accuracy: 0.9185 - val_loss: 0.3108 - val_binary_accuracy: 0.9205\n",
      "Epoch 2/25\n",
      " - 23s - loss: 0.2546 - binary_accuracy: 0.9190 - val_loss: 0.3522 - val_binary_accuracy: 0.9127\n",
      "Epoch 3/25\n",
      " - 23s - loss: 0.2536 - binary_accuracy: 0.9190 - val_loss: 0.3502 - val_binary_accuracy: 0.9192\n",
      "[CV]  architecture=[298, 256, 256, 128], batch_size=32, drop_fraction=0.25, score=0.7470801344458752, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 180.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 249083 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 32s - loss: 0.2573 - binary_accuracy: 0.9184 - val_loss: 0.2454 - val_binary_accuracy: 0.9225\n",
      "Epoch 2/25\n",
      " - 29s - loss: 0.2524 - binary_accuracy: 0.9189 - val_loss: 0.2433 - val_binary_accuracy: 0.9225\n",
      "Epoch 3/25\n",
      " - 30s - loss: 0.2516 - binary_accuracy: 0.9190 - val_loss: 0.2405 - val_binary_accuracy: 0.9226\n",
      "Epoch 4/25\n",
      " - 29s - loss: 0.2510 - binary_accuracy: 0.9189 - val_loss: 0.2411 - val_binary_accuracy: 0.9224\n",
      "Epoch 5/25\n",
      " - 30s - loss: 0.2507 - binary_accuracy: 0.9190 - val_loss: 0.2445 - val_binary_accuracy: 0.9209\n"
     ]
    }
   ],
   "source": [
    "#pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit)\n",
    "#X, Y, pipe = pre_process(phase = \"train\", preproc_pipeline = pipeline)\n",
    "\n",
    "\n",
    "patient_early_stopping = EarlyStopping(patience = 2, restore_best_weights = True)\n",
    "selu_clf = KerasClassifier(build_fn = get_selu_activation_model, \n",
    "                      validation_split = 0.1, \n",
    "                      epochs = 25, \n",
    "                      verbose = 2)\n",
    "selu_search_grid = {'drop_fraction':[None, 0.25], \n",
    "               'architecture':[[298,512,512],[298,256,256],[298,512,512,256],[298,256,256,128]],\n",
    "               'batch_size':[8,32]}\n",
    "sgs = GridSearchCV(\n",
    "    estimator = selu_clf,\n",
    "    param_grid = selu_search_grid,\n",
    "    scoring = 'roc_auc',  \n",
    "    cv = 3,\n",
    "    verbose=10,\n",
    "    fit_params = {'callbacks': [patient_early_stopping]}\n",
    ")\n",
    "\n",
    "# run test\n",
    "run_test(X, Y, \n",
    "         search = sgs, \n",
    "         experiment_name = \"NN\", \n",
    "         test_description = 'larger architectures, selu activation, smaller mini-batches',\n",
    "         pipeline_named_steps = get_pipe_named_steps(pipeline), \n",
    "         num_attribs = NUMERIC_COLS_logit, \n",
    "         cat_attribs = CATEGORY_COLS_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement Testing\n",
    "The best neural network model gets better scores than other models'. However, this success has been achieved at a cost of greater cost in computational resources.\n",
    "\n",
    "What have we learned so far about neural network architecture and training? \n",
    "* Dropout regularization does not help at all.\n",
    "* SELU activation gets slightly better results than RELU activation, but at the cost of tripling training time and increasing prediction time by 30%.\n",
    "* Batch size of 32 is better than 8.\n",
    "* The best architecture hidden layers of 256-256.\n",
    "* Test scores are consistently better than training validation scores. This is probably the result of training the model on more observations in the test phase than in training/cross-validation. In other words, neural networks seem to benefit more from increasing observations than other model types.\n",
    "\n",
    "So let us proceed to a final exploration of the hyper-parameters in the vicinity of our best results so far. The exploration will use RELU activation instead SELU in order to finish as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 307511 records\n",
      "features from previous application\n",
      "features from bureau\n",
      "features from credit card balance\n",
      "features from installments\n",
      "features from application\n",
      "start pipeline\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit)\n",
    "X, Y, pipe = pre_process(phase = \"train\", preproc_pipeline = pipeline)\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 2, restore_best_weights = True)\n",
    "clf = KerasClassifier(build_fn = get_keras_model, \n",
    "                      validation_split = 0.1, \n",
    "                      epochs = 25, \n",
    "                      verbose = 2)\n",
    "search_grid = {'architecture':[[298,320,320],[298,256,256],[298,192,192],[298,320,320,16],[298,256,256,16],[298,192,192,16]],\n",
    "               'batch_size':[32,48]}\n",
    "gs = GridSearchCV(\n",
    "    estimator = clf,\n",
    "    param_grid = search_grid,\n",
    "    scoring = 'roc_auc',  \n",
    "    cv = 5,\n",
    "    verbose=10,\n",
    "    fit_params = {'callbacks': [early_stopping]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test\n",
    "run_test(X, Y, \n",
    "         search = gs, \n",
    "         experiment_name = \"NN\", \n",
    "         test_description = 'refinement in the vicinity of previous best results',\n",
    "         pipeline_named_steps = get_pipe_named_steps(pipeline), \n",
    "         num_attribs = NUMERIC_COLS_logit, \n",
    "         cat_attribs = CATEGORY_COLS_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function: RELU vs. SELU\n",
    "The best feed-forward network architecture seems to be 320-320-16. But with which activation function? We already have the results for RELU, so let's get the results for SELU and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 307511 records\n",
      "features from previous application\n",
      "features from bureau\n",
      "features from credit card balance\n",
      "features from installments\n",
      "features from application\n",
      "start pipeline\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fe487bbefd46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m          \u001b[0mpipeline_named_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pipe_named_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m          \u001b[0mnum_attribs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNUMERIC_COLS_logit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m          cat_attribs = CATEGORY_COLS_logit)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-126b5954e8e9>\u001b[0m in \u001b[0;36mrun_test\u001b[1;34m(X, Y, search, test_description, experiment_name, pipeline_named_steps, cat_attribs, num_attribs, testSize, **fit_params)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;31m#     import pdb; pdb.set_trace()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;31m#    search.fit(X_train, y_train, **fit_params)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;31m# TODO in phase 3: calculate p-value w.r.t. baseline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit)\n",
    "X, Y, pipe = pre_process(phase = \"train\", preproc_pipeline = pipeline)\n",
    "\n",
    "patient_early_stopping = EarlyStopping(patience = 2, restore_best_weights = True)\n",
    "selu_clf = KerasClassifier(build_fn = get_selu_activation_model, \n",
    "                      validation_split = 0.1, \n",
    "                      epochs = 25, \n",
    "                      verbose = 2)\n",
    "selu_search_grid = {'architecture':[[298,320,320,16]],\n",
    "                    'batch_size':[32,48]}\n",
    "sgs = GridSearchCV(\n",
    "    estimator = selu_clf,\n",
    "    param_grid = selu_search_grid,\n",
    "    scoring = 'roc_auc',  \n",
    "    cv = 5,\n",
    "    verbose=10,\n",
    "    fit_params = {'callbacks': [patient_early_stopping]}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:643: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=32 .................\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 24s - loss: 0.2565 - binary_accuracy: 0.9184 - val_loss: 0.2433 - val_binary_accuracy: 0.9222\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.2528 - binary_accuracy: 0.9185 - val_loss: 0.2449 - val_binary_accuracy: 0.9221\n",
      "Epoch 3/25\n",
      " - 22s - loss: 0.2515 - binary_accuracy: 0.9188 - val_loss: 0.2446 - val_binary_accuracy: 0.9222\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=32, score=0.7444398841027781, total= 1.2min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=32 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 22s - loss: 0.2569 - binary_accuracy: 0.9191 - val_loss: 0.2457 - val_binary_accuracy: 0.9221\n",
      "Epoch 2/25\n",
      " - 21s - loss: 0.2519 - binary_accuracy: 0.9194 - val_loss: 0.2423 - val_binary_accuracy: 0.9221\n",
      "Epoch 3/25\n",
      " - 22s - loss: 0.2505 - binary_accuracy: 0.9194 - val_loss: 0.2507 - val_binary_accuracy: 0.9221\n",
      "Epoch 4/25\n",
      " - 22s - loss: 0.2499 - binary_accuracy: 0.9194 - val_loss: 0.2424 - val_binary_accuracy: 0.9215\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=32, score=0.7523339699212804, total= 1.5min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=32 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 23s - loss: 0.2561 - binary_accuracy: 0.9189 - val_loss: 0.2473 - val_binary_accuracy: 0.9222\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.2519 - binary_accuracy: 0.9192 - val_loss: 0.2539 - val_binary_accuracy: 0.9217\n",
      "Epoch 3/25\n",
      " - 22s - loss: 0.2511 - binary_accuracy: 0.9192 - val_loss: 0.2505 - val_binary_accuracy: 0.9223\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=32, score=0.7400759280678266, total= 1.1min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=32 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 24s - loss: 0.2548 - binary_accuracy: 0.9187 - val_loss: 0.2427 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.2519 - binary_accuracy: 0.9189 - val_loss: 0.2420 - val_binary_accuracy: 0.9214\n",
      "Epoch 3/25\n",
      " - 22s - loss: 0.2517 - binary_accuracy: 0.9189 - val_loss: 0.2422 - val_binary_accuracy: 0.9215\n",
      "Epoch 4/25\n",
      " - 22s - loss: 0.2517 - binary_accuracy: 0.9187 - val_loss: 0.2412 - val_binary_accuracy: 0.9221\n",
      "Epoch 5/25\n",
      " - 23s - loss: 0.2507 - binary_accuracy: 0.9189 - val_loss: 0.2429 - val_binary_accuracy: 0.9222\n",
      "Epoch 6/25\n",
      " - 22s - loss: 0.2498 - binary_accuracy: 0.9190 - val_loss: 0.2411 - val_binary_accuracy: 0.9222\n",
      "Epoch 7/25\n",
      " - 21s - loss: 0.2491 - binary_accuracy: 0.9190 - val_loss: 0.2416 - val_binary_accuracy: 0.9222\n",
      "Epoch 8/25\n",
      " - 22s - loss: 0.2487 - binary_accuracy: 0.9188 - val_loss: 0.2430 - val_binary_accuracy: 0.9216\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=32, score=0.7490305404902448, total= 3.0min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=32 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  7.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199267 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 22s - loss: 0.2601 - binary_accuracy: 0.9185 - val_loss: 0.2466 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 22s - loss: 0.2527 - binary_accuracy: 0.9191 - val_loss: 0.2460 - val_binary_accuracy: 0.9212\n",
      "Epoch 3/25\n",
      " - 21s - loss: 0.2511 - binary_accuracy: 0.9192 - val_loss: 0.2496 - val_binary_accuracy: 0.9192\n",
      "Epoch 4/25\n",
      " - 22s - loss: 0.2503 - binary_accuracy: 0.9192 - val_loss: 0.2469 - val_binary_accuracy: 0.9213\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=32, score=0.7529965604686525, total= 1.5min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=48 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 15s - loss: 0.2553 - binary_accuracy: 0.9186 - val_loss: 0.2417 - val_binary_accuracy: 0.9220\n",
      "Epoch 2/25\n",
      " - 15s - loss: 0.2515 - binary_accuracy: 0.9187 - val_loss: 0.2458 - val_binary_accuracy: 0.9221\n",
      "Epoch 3/25\n",
      " - 15s - loss: 0.2512 - binary_accuracy: 0.9189 - val_loss: 0.2412 - val_binary_accuracy: 0.9221\n",
      "Epoch 4/25\n",
      " - 15s - loss: 0.2506 - binary_accuracy: 0.9190 - val_loss: 0.2402 - val_binary_accuracy: 0.9223\n",
      "Epoch 5/25\n",
      " - 15s - loss: 0.2498 - binary_accuracy: 0.9188 - val_loss: 0.2404 - val_binary_accuracy: 0.9222\n",
      "Epoch 6/25\n",
      " - 15s - loss: 0.2494 - binary_accuracy: 0.9189 - val_loss: 0.2410 - val_binary_accuracy: 0.9221\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=48, score=0.7515161589219201, total= 1.5min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=48 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 10.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 15s - loss: 0.2537 - binary_accuracy: 0.9192 - val_loss: 0.2421 - val_binary_accuracy: 0.9221\n",
      "Epoch 2/25\n",
      " - 15s - loss: 0.2506 - binary_accuracy: 0.9193 - val_loss: 0.2431 - val_binary_accuracy: 0.9214\n",
      "Epoch 3/25\n",
      " - 15s - loss: 0.2500 - binary_accuracy: 0.9193 - val_loss: 0.2416 - val_binary_accuracy: 0.9220\n",
      "Epoch 4/25\n",
      " - 15s - loss: 0.2495 - binary_accuracy: 0.9192 - val_loss: 0.2443 - val_binary_accuracy: 0.9221\n",
      "Epoch 5/25\n",
      " - 14s - loss: 0.2489 - binary_accuracy: 0.9193 - val_loss: 0.2419 - val_binary_accuracy: 0.9221\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=48, score=0.7520527649564853, total= 1.3min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=48 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 11.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 15s - loss: 0.2596 - binary_accuracy: 0.9181 - val_loss: 0.2800 - val_binary_accuracy: 0.8883\n",
      "Epoch 2/25\n",
      " - 15s - loss: 0.2518 - binary_accuracy: 0.9190 - val_loss: 0.2442 - val_binary_accuracy: 0.9222\n",
      "Epoch 3/25\n",
      " - 15s - loss: 0.2496 - binary_accuracy: 0.9192 - val_loss: 0.2496 - val_binary_accuracy: 0.9221\n",
      "Epoch 4/25\n",
      " - 15s - loss: 0.2489 - binary_accuracy: 0.9191 - val_loss: 0.2406 - val_binary_accuracy: 0.9222\n",
      "Epoch 5/25\n",
      " - 15s - loss: 0.2484 - binary_accuracy: 0.9191 - val_loss: 0.2405 - val_binary_accuracy: 0.9218\n",
      "Epoch 6/25\n",
      " - 15s - loss: 0.2479 - binary_accuracy: 0.9192 - val_loss: 0.2414 - val_binary_accuracy: 0.9222\n",
      "Epoch 7/25\n",
      " - 15s - loss: 0.2474 - binary_accuracy: 0.9194 - val_loss: 0.2414 - val_binary_accuracy: 0.9222\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=48, score=0.7523006980607122, total= 1.8min\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=48 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 13.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199266 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 16s - loss: 0.2568 - binary_accuracy: 0.9185 - val_loss: 0.2410 - val_binary_accuracy: 0.9224\n",
      "Epoch 2/25\n",
      " - 14s - loss: 0.2520 - binary_accuracy: 0.9189 - val_loss: 0.2462 - val_binary_accuracy: 0.9223\n",
      "Epoch 3/25\n",
      " - 15s - loss: 0.2509 - binary_accuracy: 0.9189 - val_loss: 0.2423 - val_binary_accuracy: 0.9210\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=48, score=0.7466998591126357, total=  47.0s\n",
      "[CV] architecture=[298, 320, 320, 16], batch_size=48 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 14.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199267 samples, validate on 22141 samples\n",
      "Epoch 1/25\n",
      " - 16s - loss: 0.2540 - binary_accuracy: 0.9190 - val_loss: 0.2477 - val_binary_accuracy: 0.9213\n",
      "Epoch 2/25\n",
      " - 15s - loss: 0.2510 - binary_accuracy: 0.9192 - val_loss: 0.2549 - val_binary_accuracy: 0.9212\n",
      "Epoch 3/25\n",
      " - 15s - loss: 0.2505 - binary_accuracy: 0.9191 - val_loss: 0.2462 - val_binary_accuracy: 0.9200\n",
      "Epoch 4/25\n",
      " - 14s - loss: 0.2496 - binary_accuracy: 0.9192 - val_loss: 0.2470 - val_binary_accuracy: 0.9213\n",
      "Epoch 5/25\n",
      " - 15s - loss: 0.2487 - binary_accuracy: 0.9191 - val_loss: 0.2464 - val_binary_accuracy: 0.9206\n",
      "[CV]  architecture=[298, 320, 320, 16], batch_size=48, score=0.7538730642195899, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 15.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 249083 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 19s - loss: 0.2568 - binary_accuracy: 0.9186 - val_loss: 0.2485 - val_binary_accuracy: 0.9225\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2516 - binary_accuracy: 0.9190 - val_loss: 0.2423 - val_binary_accuracy: 0.9225\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2508 - binary_accuracy: 0.9190 - val_loss: 0.2404 - val_binary_accuracy: 0.9225\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2501 - binary_accuracy: 0.9190 - val_loss: 0.2416 - val_binary_accuracy: 0.9225\n",
      "Epoch 5/25\n",
      " - 20s - loss: 0.2491 - binary_accuracy: 0.9191 - val_loss: 0.2446 - val_binary_accuracy: 0.9224\n"
     ]
    }
   ],
   "source": [
    "# run test\n",
    "run_test(X, Y, \n",
    "         search = sgs, \n",
    "         experiment_name = \"NN\", \n",
    "         test_description = 'final test for SELU vs. RELU with best architecture (320-320-16)',\n",
    "         pipeline_named_steps = get_pipe_named_steps(pipeline), \n",
    "         num_attribs = NUMERIC_COLS_logit, \n",
    "         cat_attribs = CATEGORY_COLS_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Too close to call, so more testing ....\n",
    "The train AUC of the best RELU and SELU models were basically equivalent (.7518 and .7513, respectively). However, the SELU activation model's test AUC was modestly more favorable than the RELU model's (.755 and .752, respectively). This result is consistent with the idea that the SELU activation improves more rapidly as the amount of training data increase; however, the scores are not so disparate as to find one activation clearly better than the other.\n",
    "\n",
    "Consequently, we use 10-fold validation over the entire training set (test verification has already been done). The winner will be the activation that yields the best average training AUC over the 10-fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 249083 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 21s - loss: 0.2535 - binary_accuracy: 0.9190 - val_loss: 0.2526 - val_binary_accuracy: 0.9208\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2502 - binary_accuracy: 0.9191 - val_loss: 0.2467 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2493 - binary_accuracy: 0.9191 - val_loss: 0.2445 - val_binary_accuracy: 0.9208\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2490 - binary_accuracy: 0.9192 - val_loss: 0.2494 - val_binary_accuracy: 0.9208\n",
      "Epoch 5/25\n",
      " - 18s - loss: 0.2484 - binary_accuracy: 0.9193 - val_loss: 0.2450 - val_binary_accuracy: 0.9211\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2542 - binary_accuracy: 0.9190 - val_loss: 0.2549 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2506 - binary_accuracy: 0.9190 - val_loss: 0.2498 - val_binary_accuracy: 0.9209\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2497 - binary_accuracy: 0.9191 - val_loss: 0.2456 - val_binary_accuracy: 0.9207\n",
      "Epoch 4/25\n",
      " - 16s - loss: 0.2490 - binary_accuracy: 0.9192 - val_loss: 0.2495 - val_binary_accuracy: 0.9211\n",
      "Epoch 5/25\n",
      " - 16s - loss: 0.2490 - binary_accuracy: 0.9192 - val_loss: 0.2563 - val_binary_accuracy: 0.9207\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2535 - binary_accuracy: 0.9192 - val_loss: 0.2538 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2498 - binary_accuracy: 0.9193 - val_loss: 0.2463 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2487 - binary_accuracy: 0.9194 - val_loss: 0.2454 - val_binary_accuracy: 0.9207\n",
      "Epoch 4/25\n",
      " - 16s - loss: 0.2482 - binary_accuracy: 0.9195 - val_loss: 0.2446 - val_binary_accuracy: 0.9210\n",
      "Epoch 5/25\n",
      " - 16s - loss: 0.2474 - binary_accuracy: 0.9195 - val_loss: 0.2447 - val_binary_accuracy: 0.9208\n",
      "Epoch 6/25\n",
      " - 16s - loss: 0.2472 - binary_accuracy: 0.9196 - val_loss: 0.2456 - val_binary_accuracy: 0.9208\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2533 - binary_accuracy: 0.9194 - val_loss: 0.2474 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 25s - loss: 0.2500 - binary_accuracy: 0.9194 - val_loss: 0.2489 - val_binary_accuracy: 0.9208\n",
      "Epoch 3/25\n",
      " - 31s - loss: 0.2489 - binary_accuracy: 0.9195 - val_loss: 0.2473 - val_binary_accuracy: 0.9207\n",
      "Epoch 4/25\n",
      " - 31s - loss: 0.2483 - binary_accuracy: 0.9195 - val_loss: 0.2466 - val_binary_accuracy: 0.9209\n",
      "Epoch 5/25\n",
      " - 31s - loss: 0.2481 - binary_accuracy: 0.9196 - val_loss: 0.2483 - val_binary_accuracy: 0.9206\n",
      "Epoch 6/25\n",
      " - 31s - loss: 0.2481 - binary_accuracy: 0.9197 - val_loss: 0.2480 - val_binary_accuracy: 0.9207\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 45s - loss: 0.2537 - binary_accuracy: 0.9193 - val_loss: 0.2470 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 45s - loss: 0.2503 - binary_accuracy: 0.9193 - val_loss: 0.2474 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 31s - loss: 0.2493 - binary_accuracy: 0.9193 - val_loss: 0.2452 - val_binary_accuracy: 0.9207\n",
      "Epoch 4/25\n",
      " - 54s - loss: 0.2485 - binary_accuracy: 0.9193 - val_loss: 0.2456 - val_binary_accuracy: 0.9207\n",
      "Epoch 5/25\n",
      " - 31s - loss: 0.2480 - binary_accuracy: 0.9195 - val_loss: 0.2452 - val_binary_accuracy: 0.9209\n",
      "Epoch 6/25\n",
      " - 31s - loss: 0.2474 - binary_accuracy: 0.9195 - val_loss: 0.2448 - val_binary_accuracy: 0.9207\n",
      "Epoch 7/25\n",
      " - 31s - loss: 0.2468 - binary_accuracy: 0.9194 - val_loss: 0.2448 - val_binary_accuracy: 0.9208\n",
      "Epoch 8/25\n",
      " - 31s - loss: 0.2464 - binary_accuracy: 0.9194 - val_loss: 0.2457 - val_binary_accuracy: 0.9209\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 62s - loss: 0.2538 - binary_accuracy: 0.9190 - val_loss: 0.2466 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 48s - loss: 0.2503 - binary_accuracy: 0.9190 - val_loss: 0.2478 - val_binary_accuracy: 0.9206\n",
      "Epoch 3/25\n",
      " - 31s - loss: 0.2493 - binary_accuracy: 0.9192 - val_loss: 0.2455 - val_binary_accuracy: 0.9206\n",
      "Epoch 4/25\n",
      " - 407s - loss: 0.2485 - binary_accuracy: 0.9192 - val_loss: 0.2488 - val_binary_accuracy: 0.9211\n",
      "Epoch 5/25\n",
      " - 18s - loss: 0.2480 - binary_accuracy: 0.9192 - val_loss: 0.2461 - val_binary_accuracy: 0.9209\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2533 - binary_accuracy: 0.9190 - val_loss: 0.2530 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2500 - binary_accuracy: 0.9192 - val_loss: 0.2457 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2493 - binary_accuracy: 0.9192 - val_loss: 0.2469 - val_binary_accuracy: 0.9207\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2487 - binary_accuracy: 0.9192 - val_loss: 0.2508 - val_binary_accuracy: 0.9208\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2547 - binary_accuracy: 0.9189 - val_loss: 0.2501 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2511 - binary_accuracy: 0.9190 - val_loss: 0.2491 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2500 - binary_accuracy: 0.9190 - val_loss: 0.2460 - val_binary_accuracy: 0.9210\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2493 - binary_accuracy: 0.9190 - val_loss: 0.2457 - val_binary_accuracy: 0.9208\n",
      "Epoch 5/25\n",
      " - 18s - loss: 0.2487 - binary_accuracy: 0.9191 - val_loss: 0.2453 - val_binary_accuracy: 0.9208\n",
      "Epoch 6/25\n",
      " - 18s - loss: 0.2481 - binary_accuracy: 0.9192 - val_loss: 0.2459 - val_binary_accuracy: 0.9207\n",
      "Epoch 7/25\n",
      " - 17s - loss: 0.2480 - binary_accuracy: 0.9194 - val_loss: 0.2458 - val_binary_accuracy: 0.9210\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 17s - loss: 0.2544 - binary_accuracy: 0.9188 - val_loss: 0.2512 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 17s - loss: 0.2507 - binary_accuracy: 0.9191 - val_loss: 0.2454 - val_binary_accuracy: 0.9211\n",
      "Epoch 3/25\n",
      " - 17s - loss: 0.2496 - binary_accuracy: 0.9191 - val_loss: 0.2462 - val_binary_accuracy: 0.9207\n",
      "Epoch 4/25\n",
      " - 17s - loss: 0.2487 - binary_accuracy: 0.9193 - val_loss: 0.2453 - val_binary_accuracy: 0.9208\n",
      "Epoch 5/25\n",
      " - 17s - loss: 0.2482 - binary_accuracy: 0.9194 - val_loss: 0.2454 - val_binary_accuracy: 0.9207\n",
      "Epoch 6/25\n",
      " - 17s - loss: 0.2476 - binary_accuracy: 0.9194 - val_loss: 0.2455 - val_binary_accuracy: 0.9209\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 18s - loss: 0.2541 - binary_accuracy: 0.9189 - val_loss: 0.2454 - val_binary_accuracy: 0.9208\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2510 - binary_accuracy: 0.9190 - val_loss: 0.2441 - val_binary_accuracy: 0.9208\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2500 - binary_accuracy: 0.9189 - val_loss: 0.2484 - val_binary_accuracy: 0.9208\n",
      "Epoch 4/25\n",
      " - 18s - loss: 0.2492 - binary_accuracy: 0.9191 - val_loss: 0.2447 - val_binary_accuracy: 0.9207\n",
      "Train on 249083 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2553 - binary_accuracy: 0.9185 - val_loss: 0.2474 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 18s - loss: 0.2510 - binary_accuracy: 0.9190 - val_loss: 0.2501 - val_binary_accuracy: 0.9208\n",
      "Epoch 3/25\n",
      " - 18s - loss: 0.2500 - binary_accuracy: 0.9190 - val_loss: 0.2467 - val_binary_accuracy: 0.9209\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2490 - binary_accuracy: 0.9191 - val_loss: 0.2458 - val_binary_accuracy: 0.9208\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2481 - binary_accuracy: 0.9192 - val_loss: 0.2453 - val_binary_accuracy: 0.9211\n",
      "Epoch 6/25\n",
      " - 18s - loss: 0.2477 - binary_accuracy: 0.9192 - val_loss: 0.2476 - val_binary_accuracy: 0.9204\n",
      "Epoch 7/25\n",
      " - 19s - loss: 0.2475 - binary_accuracy: 0.9191 - val_loss: 0.2462 - val_binary_accuracy: 0.9208\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2592 - binary_accuracy: 0.9181 - val_loss: 0.2514 - val_binary_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2516 - binary_accuracy: 0.9191 - val_loss: 0.2493 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 19s - loss: 0.2504 - binary_accuracy: 0.9191 - val_loss: 0.2470 - val_binary_accuracy: 0.9205\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2495 - binary_accuracy: 0.9191 - val_loss: 0.2476 - val_binary_accuracy: 0.9208\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2491 - binary_accuracy: 0.9191 - val_loss: 0.2489 - val_binary_accuracy: 0.9208\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2550 - binary_accuracy: 0.9188 - val_loss: 0.2485 - val_binary_accuracy: 0.9205\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2499 - binary_accuracy: 0.9193 - val_loss: 0.2535 - val_binary_accuracy: 0.9206\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2484 - binary_accuracy: 0.9193 - val_loss: 0.2463 - val_binary_accuracy: 0.9208\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2476 - binary_accuracy: 0.9194 - val_loss: 0.2449 - val_binary_accuracy: 0.9206\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2471 - binary_accuracy: 0.9193 - val_loss: 0.2459 - val_binary_accuracy: 0.9209\n",
      "Epoch 6/25\n",
      " - 19s - loss: 0.2465 - binary_accuracy: 0.9194 - val_loss: 0.2458 - val_binary_accuracy: 0.9208\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2569 - binary_accuracy: 0.9185 - val_loss: 0.2466 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2505 - binary_accuracy: 0.9194 - val_loss: 0.2488 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2492 - binary_accuracy: 0.9194 - val_loss: 0.2553 - val_binary_accuracy: 0.9195\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2549 - binary_accuracy: 0.9190 - val_loss: 0.2517 - val_binary_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2508 - binary_accuracy: 0.9192 - val_loss: 0.2460 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2498 - binary_accuracy: 0.9193 - val_loss: 0.2549 - val_binary_accuracy: 0.9209\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2493 - binary_accuracy: 0.9193 - val_loss: 0.2459 - val_binary_accuracy: 0.9207\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2490 - binary_accuracy: 0.9192 - val_loss: 0.2459 - val_binary_accuracy: 0.9207\n",
      "Epoch 6/25\n",
      " - 19s - loss: 0.2487 - binary_accuracy: 0.9192 - val_loss: 0.2459 - val_binary_accuracy: 0.9209\n",
      "Epoch 7/25\n",
      " - 19s - loss: 0.2478 - binary_accuracy: 0.9193 - val_loss: 0.2474 - val_binary_accuracy: 0.9200\n",
      "Epoch 8/25\n",
      " - 19s - loss: 0.2473 - binary_accuracy: 0.9193 - val_loss: 0.2478 - val_binary_accuracy: 0.9202\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2558 - binary_accuracy: 0.9185 - val_loss: 0.2510 - val_binary_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2506 - binary_accuracy: 0.9189 - val_loss: 0.2474 - val_binary_accuracy: 0.9210\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2496 - binary_accuracy: 0.9191 - val_loss: 0.2549 - val_binary_accuracy: 0.9206\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2488 - binary_accuracy: 0.9191 - val_loss: 0.2462 - val_binary_accuracy: 0.9203\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2483 - binary_accuracy: 0.9190 - val_loss: 0.2474 - val_binary_accuracy: 0.9201\n",
      "Epoch 6/25\n",
      " - 19s - loss: 0.2474 - binary_accuracy: 0.9192 - val_loss: 0.2450 - val_binary_accuracy: 0.9209\n",
      "Epoch 7/25\n",
      " - 19s - loss: 0.2468 - binary_accuracy: 0.9192 - val_loss: 0.2500 - val_binary_accuracy: 0.9207\n",
      "Epoch 8/25\n",
      " - 19s - loss: 0.2465 - binary_accuracy: 0.9192 - val_loss: 0.2456 - val_binary_accuracy: 0.9208\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2560 - binary_accuracy: 0.9184 - val_loss: 0.2481 - val_binary_accuracy: 0.9206\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2504 - binary_accuracy: 0.9191 - val_loss: 0.2510 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2488 - binary_accuracy: 0.9191 - val_loss: 0.2458 - val_binary_accuracy: 0.9208\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2479 - binary_accuracy: 0.9192 - val_loss: 0.2468 - val_binary_accuracy: 0.9207\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2474 - binary_accuracy: 0.9192 - val_loss: 0.2481 - val_binary_accuracy: 0.9173\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2537 - binary_accuracy: 0.9188 - val_loss: 0.2469 - val_binary_accuracy: 0.9207\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2510 - binary_accuracy: 0.9191 - val_loss: 0.2467 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2500 - binary_accuracy: 0.9188 - val_loss: 0.2452 - val_binary_accuracy: 0.9208\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2490 - binary_accuracy: 0.9189 - val_loss: 0.2454 - val_binary_accuracy: 0.9208\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2483 - binary_accuracy: 0.9191 - val_loss: 0.2500 - val_binary_accuracy: 0.9212\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 21s - loss: 0.2561 - binary_accuracy: 0.9185 - val_loss: 0.2470 - val_binary_accuracy: 0.9208\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2510 - binary_accuracy: 0.9188 - val_loss: 0.2489 - val_binary_accuracy: 0.9207\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2502 - binary_accuracy: 0.9190 - val_loss: 0.2534 - val_binary_accuracy: 0.9206\n",
      "Train on 249084 samples, validate on 27676 samples\n",
      "Epoch 1/25\n",
      " - 20s - loss: 0.2557 - binary_accuracy: 0.9185 - val_loss: 0.2457 - val_binary_accuracy: 0.9208\n",
      "Epoch 2/25\n",
      " - 20s - loss: 0.2515 - binary_accuracy: 0.9189 - val_loss: 0.2443 - val_binary_accuracy: 0.9208\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2502 - binary_accuracy: 0.9190 - val_loss: 0.2483 - val_binary_accuracy: 0.9208\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2496 - binary_accuracy: 0.9190 - val_loss: 0.2452 - val_binary_accuracy: 0.9208\n",
      "relu mean: 0.7521549356086517, array: [0.75295964 0.75097409 0.75285105 0.75408708 0.74834872 0.74006666\n",
      " 0.74895061 0.76222011 0.75729899 0.75379241]\n",
      "selu mean: 0.752515647293923, array: [0.75632028 0.7560016  0.75380479 0.75000518 0.74875307 0.7447164\n",
      " 0.74962386 0.76136709 0.75219222 0.752372  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit)\n",
    "X, Y, pipe = pre_process(phase = \"train\", preproc_pipeline = pipeline)\n",
    "\n",
    "patient_early_stopping = EarlyStopping(patience = 2, restore_best_weights = True)\n",
    "final_architecture = [298,320,320,16]\n",
    "\n",
    "def get_relu_with_final_arch():\n",
    "    return get_keras_model(architecture = final_architecture)\n",
    "\n",
    "relu_clf = KerasClassifier(build_fn = get_relu_with_final_arch, \n",
    "                      validation_split = 0.1, \n",
    "                      epochs = 25, \n",
    "                      verbose = 2)\n",
    "\n",
    "def get_selu_with_final_arch():\n",
    "    return get_selu_activation_model(architecture = final_architecture)\n",
    "\n",
    "selu_clf = KerasClassifier(build_fn = get_selu_with_final_arch, \n",
    "                      validation_split = 0.1, \n",
    "                      epochs = 25, \n",
    "                      verbose = 2)\n",
    "\n",
    "def get_cross_val_scores(clf):\n",
    "    return cross_val_score(clf,\n",
    "                           X, Y,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           fit_params={'callbacks': [patient_early_stopping],\n",
    "                                       'batch_size': 48}\n",
    "                          )\n",
    "\n",
    "relu_scores = get_cross_val_scores(relu_clf)\n",
    "selu_scores = get_cross_val_scores(selu_clf)\n",
    "\n",
    "print(f\"relu mean: {np.mean(relu_scores)}, array: {relu_scores}\")\n",
    "print(f\"selu mean: {np.mean(selu_scores)}, array: {selu_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Kaggle submission for the winning neural network\n",
    "It was a close race, but the victory goes to SELU activation. Let's prepare the Kaggle submission. We train two models: \n",
    "* The first is monitored against a holdout validation set of 10% to see how many epochs to run before the overfitting threshold is crossed. \n",
    "* The second is trained with the entire training set for the number of epochs identified in the first model's training.\n",
    "\n",
    "The predictions of both models will be submitted to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 307511 records\n",
      "features from previous application\n",
      "features from bureau\n",
      "features from credit card balance\n",
      "features from installments\n",
      "features from application\n",
      "start pipeline\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 276759 samples, validate on 30752 samples\n",
      "Epoch 1/25\n",
      " - 21s - loss: 0.2541 - binary_accuracy: 0.9188 - val_loss: 0.2468 - val_binary_accuracy: 0.9209\n",
      "Epoch 2/25\n",
      " - 19s - loss: 0.2495 - binary_accuracy: 0.9192 - val_loss: 0.2461 - val_binary_accuracy: 0.9209\n",
      "Epoch 3/25\n",
      " - 19s - loss: 0.2486 - binary_accuracy: 0.9191 - val_loss: 0.2444 - val_binary_accuracy: 0.9209\n",
      "Epoch 4/25\n",
      " - 19s - loss: 0.2479 - binary_accuracy: 0.9190 - val_loss: 0.2448 - val_binary_accuracy: 0.9212\n",
      "Epoch 5/25\n",
      " - 19s - loss: 0.2474 - binary_accuracy: 0.9192 - val_loss: 0.2459 - val_binary_accuracy: 0.9210\n",
      "loaded 48744 records\n",
      "features from previous application\n",
      "features from bureau\n",
      "features from credit card balance\n",
      "features from installments\n",
      "features from application\n",
      "start pipeline\n",
      "loaded 48744 records\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'application_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-86289b6c827f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_clf_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0msubmit_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"application_test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SK_ID_CURR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0msubmit_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TARGET'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0msubmit_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission_val.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'application_test'"
     ]
    }
   ],
   "source": [
    "pipeline = get_standard_pipeline(cat_attribs=CATEGORY_COLS_logit, num_attribs=NUMERIC_COLS_logit)\n",
    "X, Y, pipe = pre_process(phase = \"train\", preproc_pipeline = pipeline)\n",
    "\n",
    "patient_early_stopping = EarlyStopping(patience = 2, restore_best_weights = True)\n",
    "best_clf_val = get_selu_with_final_arch()\n",
    "best_clf_val.fit(X, Y, \n",
    "                 batch_size = 48, \n",
    "                 epochs = 25, \n",
    "                 verbose = 2, \n",
    "                 callbacks = [patient_early_stopping], \n",
    "                 validation_split=0.1)\n",
    "\n",
    "test_data, _, _ = pre_process(phase = 'test', preproc_pipeline = pipeline)\n",
    "preds = best_clf_val.predict_proba(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = load_data(\"application_test\")[['SK_ID_CURR']]\n",
    "submit_df['TARGET'] = preds\n",
    "submit_df.to_csv(\"submission_val.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 21s - loss: 0.2527 - binary_accuracy: 0.9191\n",
      "Epoch 2/3\n",
      " - 20s - loss: 0.2504 - binary_accuracy: 0.9192\n",
      "Epoch 3/3\n",
      " - 21s - loss: 0.2495 - binary_accuracy: 0.9191\n"
     ]
    }
   ],
   "source": [
    "best_clf = get_selu_with_final_arch()\n",
    "best_clf.fit(X, Y, \n",
    "             batch_size = 48, \n",
    "             epochs = 3, \n",
    "             verbose = 2)\n",
    "\n",
    "preds = best_clf.predict_proba(test_data)\n",
    "submit_df = load_data(\"application_test\")[['SK_ID_CURR']]\n",
    "submit_df['TARGET'] = preds\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score set as holdout validation\n",
    "Using a portion of your training data for holdout validation means you know when the model is starting to overfit. However, your neural network tends to get lower scores because its accuracy grows proportionately to the amount of training data, and you are not training with all your data. The scores on the initial NN Kaggle submissions demonstrate this trade-off:\n",
    "\n",
    "![Initial NN submissions](NN_init_submissions.png) \n",
    "\n",
    "Is there a way to avoid this trade-off so we can train the neural network on all the data, while still finding the optimal number of training epochs? Yes: use the Kaggle scoreboard test set as a holdout validation set! In the cells below, we increase the number of epochs by one with each submission until we have passed the optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " - 21s - loss: 0.2536 - binary_accuracy: 0.9192\n",
      "Epoch 2/4\n",
      " - 21s - loss: 0.2504 - binary_accuracy: 0.9193\n",
      "Epoch 3/4\n",
      " - 21s - loss: 0.2498 - binary_accuracy: 0.9193\n",
      "Epoch 4/4\n",
      " - 21s - loss: 0.2488 - binary_accuracy: 0.9194\n"
     ]
    }
   ],
   "source": [
    "# Try one more epoch => 4\n",
    "best_clf = get_selu_with_final_arch()\n",
    "best_clf.fit(X, Y, \n",
    "             batch_size = 48, \n",
    "             epochs = 4, \n",
    "             verbose = 2)\n",
    "\n",
    "preds = best_clf.predict_proba(test_data)\n",
    "submit_df = load_data(\"application_test\")[['SK_ID_CURR']]\n",
    "submit_df['TARGET'] = preds\n",
    "submit_df.to_csv(\"submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 22s - loss: 0.2550 - binary_accuracy: 0.9188\n",
      "Epoch 2/5\n",
      " - 21s - loss: 0.2503 - binary_accuracy: 0.9193\n",
      "Epoch 3/5\n",
      " - 21s - loss: 0.2493 - binary_accuracy: 0.9193\n",
      "Epoch 4/5\n",
      " - 21s - loss: 0.2485 - binary_accuracy: 0.9193\n",
      "Epoch 5/5\n",
      " - 21s - loss: 0.2479 - binary_accuracy: 0.9192\n"
     ]
    }
   ],
   "source": [
    "# Try one more epoch => 5\n",
    "best_clf = get_selu_with_final_arch()\n",
    "best_clf.fit(X, Y, \n",
    "             batch_size = 48, \n",
    "             epochs = 5, \n",
    "             verbose = 2)\n",
    "\n",
    "preds = best_clf.predict_proba(test_data)\n",
    "submit_df = load_data(\"application_test\")[['SK_ID_CURR']]\n",
    "submit_df['TARGET'] = preds\n",
    "submit_df.to_csv(\"submission5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      " - 22s - loss: 0.2564 - binary_accuracy: 0.9186\n",
      "Epoch 2/6\n",
      " - 21s - loss: 0.2501 - binary_accuracy: 0.9193\n",
      "Epoch 3/6\n",
      " - 21s - loss: 0.2487 - binary_accuracy: 0.9193\n",
      "Epoch 4/6\n",
      " - 21s - loss: 0.2480 - binary_accuracy: 0.9193\n",
      "Epoch 5/6\n",
      " - 21s - loss: 0.2475 - binary_accuracy: 0.9193\n",
      "Epoch 6/6\n",
      " - 21s - loss: 0.2472 - binary_accuracy: 0.9193\n"
     ]
    }
   ],
   "source": [
    "# Try one more epoch => 6\n",
    "best_clf = get_selu_with_final_arch()\n",
    "best_clf.fit(X, Y, \n",
    "             batch_size = 48, \n",
    "             epochs = 6, \n",
    "             verbose = 2)\n",
    "\n",
    "preds = best_clf.predict_proba(test_data)\n",
    "submit_df = load_data(\"application_test\")[['SK_ID_CURR']]\n",
    "submit_df['TARGET'] = preds\n",
    "submit_df.to_csv(\"submission6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      " - 23s - loss: 0.2538 - binary_accuracy: 0.9191\n",
      "Epoch 2/7\n",
      " - 22s - loss: 0.2504 - binary_accuracy: 0.9192\n",
      "Epoch 3/7\n",
      " - 22s - loss: 0.2495 - binary_accuracy: 0.9192\n",
      "Epoch 4/7\n",
      " - 21s - loss: 0.2487 - binary_accuracy: 0.9192\n",
      "Epoch 5/7\n",
      " - 21s - loss: 0.2479 - binary_accuracy: 0.9191\n",
      "Epoch 6/7\n",
      " - 21s - loss: 0.2470 - binary_accuracy: 0.9193\n",
      "Epoch 7/7\n",
      " - 21s - loss: 0.2469 - binary_accuracy: 0.9193\n"
     ]
    }
   ],
   "source": [
    "# Try one more epoch => 7\n",
    "best_clf = get_selu_with_final_arch()\n",
    "best_clf.fit(X, Y, \n",
    "             batch_size = 48, \n",
    "             epochs = 7, \n",
    "             verbose = 2)\n",
    "\n",
    "preds = best_clf.predict_proba(test_data)\n",
    "submit_df = load_data(\"application_test\")[['SK_ID_CURR']]\n",
    "submit_df['TARGET'] = preds\n",
    "submit_df.to_csv(\"submission7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seven epochs clearly reach the overfitting zone, as seen below:\n",
    "    \n",
    "![NN increased epochs submissions](NN_later_submissions.png)\n",
    "\n",
    "Using the public scoreboard as validation set, we see that 6 training epochs provide the neural network with the best generalization capability. The final AUC score is a healthy **0.75436**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMZtUi4vQzK2"
   },
   "source": [
    "# Kaggle submission via the command line API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "S1qiCFmwQzK2",
    "outputId": "923634f2-e05f-408a-b2ad-11a6e96f6a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Home Credit Default Risk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/921k [00:00<?, ?B/s]\n",
      " 10%|9         | 88.0k/921k [00:00<00:01, 798kB/s]\n",
      "100%|##########| 921k/921k [00:00<00:00, 961kB/s] \n"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit -c home-credit-default-risk -f submission7.csv -m \"NN 320-320-26 7 epochs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6gay8MEQzK7"
   },
   "source": [
    "## report submission\n",
    "\n",
    "Click on this [link](https://www.kaggle.com/c/home-credit-default-risk/submissions?sortBy=date&group=all&page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ifGCzK9wQzK7"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tz-yUvk5QzK8"
   },
   "source": [
    "# References\n",
    "\n",
    "Some of the material in this notebook has been adopted from [here](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction/notebook).\n",
    "\n",
    "The research paper that introduced scaled exponential linear unit activation is available [here](https://arxiv.org/abs/1706.02515).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HCDR-Submission.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
